#!/usr/bin/env python3
"""
ğŸ§ª Script automatizado para Laboratorio de Experimentos en Lote
Ejecuta los experimentos solicitados de forma sistemÃ¡tica
"""
import sys
import os
import time
from pathlib import Path

# Configure GPU environment first
def configure_gpu_environment():
    conda_prefix = os.environ.get('CONDA_PREFIX', '')
    if conda_prefix:
        os.environ['CUDA_HOME'] = conda_prefix
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
        lib_paths = [f'{conda_prefix}/lib', f'{conda_prefix}/lib64']
        existing_ld = os.environ.get('LD_LIBRARY_PATH', '')
        if existing_ld:
            lib_paths.append(existing_ld)
        clean_ld = ':'.join(lib_paths)
        os.environ['LD_LIBRARY_PATH'] = clean_ld
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'

configure_gpu_environment()

# Import after GPU configuration
sys.path.insert(0, 'src')
from data_processor import TextGenerator
from model import ModelManager
import tensorflow as tf

def load_model_and_tokenizer():
    """Load the best available model with metadata."""
    model_path = "models/robo_poet_model_20250821_203057.h5"
    metadata_path = "models/robo_poet_model_20250821_203057_metadata.json"
    
    print("ğŸ“š Cargando modelo y tokenizer...")
    
    # Load model
    model_manager = ModelManager()
    model = model_manager.load_model(model_path)
    
    if model is None:
        raise Exception("No se pudo cargar el modelo")
    
    # Load metadata
    import json
    with open(metadata_path) as f:
        metadata = json.load(f)
    
    char_to_idx = metadata['char_to_idx']
    idx_to_char = {int(k): v for k, v in metadata['idx_to_char'].items()}
    
    generator = TextGenerator(model, char_to_idx, idx_to_char)
    
    print(f"âœ… Modelo cargado: {len(char_to_idx)} caracteres en vocabulario")
    return generator

def experiment_1_temperature_sweep():
    """ğŸŒ¡ï¸ Experimento 1: Barrido de Temperature"""
    print("\nğŸ§ª EXPERIMENTO 1: BARRIDO DE TEMPERATURE")
    print("=" * 60)
    
    generator = load_model_and_tokenizer()
    
    # Parameters
    seed = "The power of knowledge"
    length = 150
    temperatures = [0.4, 0.6, 0.8, 1.0, 1.2]
    
    print(f"ğŸŒ± Seed: '{seed}'")
    print(f"ğŸ“ Longitud: {length}")
    print(f"ğŸŒ¡ï¸ Temperatures: {temperatures}")
    print("=" * 60)
    
    results = []
    
    for i, temp in enumerate(temperatures, 1):
        print(f"\nğŸŒ¡ï¸ TEMPERATURE {i}/{len(temperatures)}: {temp}")
        print("-" * 40)
        
        start_time = time.time()
        result = generator.generate(seed, length, temp)
        gen_time = time.time() - start_time
        
        # Basic analysis
        words = len(result.split())
        unique_words = len(set(result.split()))
        diversity = unique_words / words if words > 0 else 0
        
        results.append({
            'temperature': temp,
            'result': result,
            'time': gen_time,
            'chars': len(result),
            'words': words,
            'unique_words': unique_words,
            'diversity': diversity
        })
        
        print(f"ğŸ“ Resultado:")
        print(result)
        print(f"\nğŸ“Š MÃ©tricas:")
        print(f"   â±ï¸ Tiempo: {gen_time:.2f}s")
        print(f"   ğŸ“ Palabras: {words} (Ãºnicas: {unique_words})")
        print(f"   ğŸ¨ Diversidad: {diversity:.3f}")
        print(f"   âš¡ Velocidad: {len(result)/gen_time:.1f} chars/s")
    
    # Summary analysis
    print(f"\nğŸ“ˆ ANÃLISIS COMPARATIVO")
    print("=" * 50)
    print("ğŸŒ¡ï¸  Temperature | Diversidad | Palabras | Coherencia")
    print("-" * 50)
    
    for r in results:
        # Simple coherence heuristic: fewer repeated trigrams = more coherent
        text = r['result'].lower()
        trigrams = [text[i:i+3] for i in range(len(text)-2)]
        repeated_trigrams = len(trigrams) - len(set(trigrams))
        coherence_score = 1 - (repeated_trigrams / len(trigrams)) if trigrams else 0
        
        print(f"    {r['temperature']:4.1f}     |   {r['diversity']:.3f}    |    {r['words']:3d}    |   {coherence_score:.3f}")
    
    # Recommendations
    print(f"\nğŸ’¡ RECOMENDACIONES:")
    best_balance = min(results, key=lambda x: abs(x['diversity'] - 0.7))  # Target ~70% diversity
    best_coherence = max(results, key=lambda x: x['words'] / (x['result'].count(' the ') + 1))  # Less repetition
    
    print(f"   ğŸ¯ Mejor balance creatividad/coherencia: T={best_balance['temperature']}")
    print(f"   ğŸ“ Mejor coherencia aparente: T={best_coherence['temperature']}")
    
    return results

def experiment_2_length_variation():
    """ğŸ“ Experimento 2: VariaciÃ³n de Longitud"""
    print("\nğŸ§ª EXPERIMENTO 2: VARIACIÃ“N DE LONGITUD")
    print("=" * 60)
    
    generator = load_model_and_tokenizer()
    
    # Parameters
    seed = "The power of knowledge"
    temperature = 0.6
    lengths = [50, 100, 150, 200]
    
    print(f"ğŸŒ± Seed: '{seed}'")
    print(f"ğŸŒ¡ï¸ Temperature: {temperature}")
    print(f"ğŸ“ Longitudes: {lengths}")
    print("=" * 60)
    
    results = []
    
    for i, length in enumerate(lengths, 1):
        print(f"\nğŸ“ LONGITUD {i}/{len(lengths)}: {length}")
        print("-" * 40)
        
        start_time = time.time()
        result = generator.generate(seed, length, temperature)
        gen_time = time.time() - start_time
        
        # Quality metrics
        words = len(result.split())
        sentences = result.count('.') + result.count('!') + result.count('?')
        avg_word_length = sum(len(word) for word in result.split()) / words if words > 0 else 0
        
        results.append({
            'length': length,
            'result': result,
            'time': gen_time,
            'actual_chars': len(result),
            'words': words,
            'sentences': sentences,
            'avg_word_length': avg_word_length
        })
        
        print(f"ğŸ“ Resultado:")
        print(result)
        print(f"\nğŸ“Š MÃ©tricas:")
        print(f"   ğŸ“ Chars generados: {len(result)}/{length}")
        print(f"   ğŸ“ Palabras: {words}")
        print(f"   ğŸ“„ Oraciones: {sentences}")
        print(f"   ğŸ“ Promedio palabra: {avg_word_length:.1f} chars")
        print(f"   âš¡ Velocidad: {len(result)/gen_time:.1f} chars/s")
    
    # Analysis
    print(f"\nğŸ“ˆ ANÃLISIS POR LONGITUD")
    print("=" * 50)
    print("Longitud | Palabras | Oraciones | Calidad")
    print("-" * 50)
    
    for r in results:
        quality_score = (r['words'] / r['actual_chars']) * 100  # Words per 100 chars
        print(f"   {r['length']:3d}   |   {r['words']:3d}    |     {r['sentences']:2d}     | {quality_score:.1f}%")
    
    return results

def experiment_3_multiple_seeds():
    """ğŸŒ± Experimento 3: MÃºltiples Seeds"""
    print("\nğŸ§ª EXPERIMENTO 3: MÃšLTIPLES SEEDS")
    print("=" * 60)
    
    generator = load_model_and_tokenizer()
    
    # Parameters
    seeds = ["The art of", "In the beginning", "The secret to"]
    temperature = 0.6
    length = 150
    
    print(f"ğŸŒ± Seeds: {seeds}")
    print(f"ğŸŒ¡ï¸ Temperature: {temperature}")
    print(f"ğŸ“ Longitud: {length}")
    print("=" * 60)
    
    results = []
    
    for i, seed in enumerate(seeds, 1):
        print(f"\nğŸŒ± SEED {i}/{len(seeds)}: '{seed}'")
        print("-" * 40)
        
        start_time = time.time()
        result = generator.generate(seed, length, temperature)
        gen_time = time.time() - start_time
        
        # Consistency metrics
        words = len(result.split())
        unique_words = len(set(result.split()))
        capitalized_words = sum(1 for word in result.split() if word and word[0].isupper())
        
        results.append({
            'seed': seed,
            'result': result,
            'time': gen_time,
            'chars': len(result),
            'words': words,
            'unique_words': unique_words,
            'capitalized_words': capitalized_words
        })
        
        print(f"ğŸ“ Resultado:")
        print(result)
        print(f"\nğŸ“Š MÃ©tricas:")
        print(f"   ğŸ“ Palabras: {words} (Ãºnicas: {unique_words})")
        print(f"   ğŸ”¤ Palabras capitalizadas: {capitalized_words}")
        print(f"   âš¡ Velocidad: {len(result)/gen_time:.1f} chars/s")
    
    # Consistency analysis
    print(f"\nğŸ“ˆ ANÃLISIS DE CONSISTENCIA")
    print("=" * 50)
    
    avg_words = sum(r['words'] for r in results) / len(results)
    avg_diversity = sum(r['unique_words']/r['words'] for r in results) / len(results)
    
    print(f"ğŸ“Š EstadÃ­sticas promedio:")
    print(f"   ğŸ“ Palabras: {avg_words:.1f}")
    print(f"   ğŸ¨ Diversidad: {avg_diversity:.3f}")
    
    print(f"\nğŸ¯ Variabilidad por seed:")
    for r in results:
        diversity = r['unique_words'] / r['words']
        print(f"   '{r['seed']}': {r['words']} palabras, {diversity:.3f} diversidad")
    
    return results

def main():
    """Ejecutar todos los experimentos."""
    print("ğŸ§ª LABORATORIO DE EXPERIMENTOS EN LOTE")
    print("ğŸ¯ EvaluaciÃ³n sistemÃ¡tica del modelo LSTM")
    print("=" * 70)
    
    try:
        # Experiment 1: Temperature sweep
        temp_results = experiment_1_temperature_sweep()
        
        print("\n" + "="*70)
        time.sleep(2)  # Brief pause between experiments
        
        # Experiment 2: Length variation
        length_results = experiment_2_length_variation()
        
        print("\n" + "="*70)
        time.sleep(2)
        
        # Experiment 3: Multiple seeds
        seed_results = experiment_3_multiple_seeds()
        
        # Final recommendations
        print("\nğŸ¯ RECOMENDACIONES FINALES")
        print("=" * 50)
        
        # Find optimal temperature based on diversity balance
        best_temp = 0.6  # Conservative default
        if temp_results:
            balanced = [r for r in temp_results if 0.6 <= r['diversity'] <= 0.8]
            if balanced:
                best_temp = min(balanced, key=lambda x: x['temperature'])['temperature']
        
        # Find optimal length based on word density
        best_length = 150  # Default
        if length_results:
            best_length = max(length_results, key=lambda x: x['words']/x['actual_chars'])['length']
        
        print(f"ğŸŒ¡ï¸  Temperature Ã³ptima: {best_temp}")
        print(f"ğŸ“ Longitud Ã³ptima: {best_length}")
        print(f"ğŸŒ± Seed mÃ¡s consistente: 'The art of' (tÃ­picamente)")
        
        print(f"\nâœ… Experimentos completados exitosamente")
        
    except Exception as e:
        print(f"âŒ Error durante experimentos: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()