#!/usr/bin/env python3
"""
Robo-Poet Academic Framework Orchestrator

Main orchestrator for the modular academic text generation framework.
Coordinates all components and provides unified entry point.

Author: ML Academic Framework
Version: 2.1 - Modular Architecture
Hardware: Optimized for NVIDIA RTX 2000 Ada
Platform: WSL2 + Kali Linux + Windows 11
"""

import sys
import argparse
from pathlib import Path
from typing import Optional, Dict, List

# Conditional numpy import for testing
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("‚ö†Ô∏è Numpy no disponible - algunas funcionalidades limitadas")

# Import core modules safely
import os
import json

# Configure environment for potential GPU use
conda_prefix = os.getenv('CONDA_PREFIX', '/usr/local')
if conda_prefix != '/usr/local':
    os.environ['CUDA_HOME'] = conda_prefix
    os.environ['LD_LIBRARY_PATH'] = f'{conda_prefix}/lib:{conda_prefix}/lib64:{os.environ.get("LD_LIBRARY_PATH", "")}'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    # PyTorch environment optimizations

# Configure PyTorch environment
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'

# Import with fallbacks
gpu_available = False
torch_module = None

# Try to import PyTorch
try:
    import torch
    torch_module = torch
    gpu_available = torch.cuda.is_available()
    if gpu_available:
        print(f"üî• PyTorch GPU available: {torch.cuda.get_device_name(0)}")
except ImportError:
    print("‚ö†Ô∏è PyTorch no disponible - modo CPU solamente")

try:
    from core.unified_config import get_config
except ImportError:
    # Fallback to basic config
    def get_config():
        from types import SimpleNamespace
        return SimpleNamespace(
            gpu=SimpleNamespace(mixed_precision=True, memory_growth=True),
            model=SimpleNamespace(batch_size=32, epochs=10),
            system=SimpleNamespace(debug=True)
        )

# GPU detection with PyTorch
try:
    if torch_module and torch_module.cuda.is_available():
        gpu_available = True
        print(f"üéØ PyTorch GPU funcionando correctamente: {torch_module.cuda.get_device_name(0)}")
    else:
        gpu_available = False
        if torch_module:
            print("‚ö†Ô∏è PyTorch disponible pero GPU no detectada")
        else:
            print("‚ö†Ô∏è PyTorch no disponible")
except Exception as e:
    print(f"‚ö†Ô∏è GPU no disponible, continuando sin GPU: {e}")
    gpu_available = False

# Import framework components with fallbacks
try:
    from interface.menu_system import AcademicMenuSystem
except ImportError as e:
    print(f"‚ö†Ô∏è Menu system not available: {e}")
    AcademicMenuSystem = None

try:
    from interface.phase1_training import Phase1TrainingInterface
except ImportError as e:
    print(f"‚ö†Ô∏è Phase1 interface not available: {e}")
    Phase1TrainingInterface = None

try:
    from interface.phase2_generation import Phase2GenerationInterface
except ImportError as e:
    print(f"‚ö†Ô∏è Phase2 interface not available: {e}")
    Phase2GenerationInterface = None

try:
    from utils.file_manager import FileManager
except ImportError as e:
    print(f"‚ö†Ô∏è File manager not available: {e}")
    FileManager = None

try:
    from utils.display_utils import DisplayUtils
except ImportError as e:
    print(f"‚ö†Ô∏è Display utils not available: {e}")
    DisplayUtils = None

try:
    from utils.input_validator import InputValidator
except ImportError as e:
    print(f"‚ö†Ô∏è Input validator not available: {e}")
    InputValidator = None

# Import PyTorch model components
try:
    from model_pytorch import create_model, RoboPoetModel
    MODEL_TYPE = "PyTorch GPT"
    print("üöÄ Using PyTorch GPT model (modern transformer architecture)")
except ImportError as e:
    print(f"‚ùå PyTorch model not available: {e}")
    print("   Please ensure PyTorch is installed and robo-poet-pytorch directory exists")
    create_model = None
    RoboPoetModel = None
    MODEL_TYPE = "PyTorch GPT (Not Available)"


class RoboPoetOrchestrator:
    """Main orchestrator for the Robo-Poet Academic Framework."""
    
    def __init__(self):
        """Initialize orchestrator with all components."""
        self.config = get_config()
        
        # Show current model type
        print(f"ü§ñ Model System: {MODEL_TYPE}")
        
        # Academic Performance GPU Requirement
        if torch_module and not torch_module.cuda.is_available():
            print("üéì ACADEMIC PERFORMANCE WARNING:")
            print("   üìö GPU/CUDA not available - academic benchmarks require GPU")
            print("   üîß Install CUDA-enabled PyTorch for optimal performance")
        elif torch_module and torch_module.cuda.is_available():
            print(f"üî• Academic Performance Mode: GPU Available")
            print(f"   üéÆ GPU: {torch_module.cuda.get_device_name(0)}")
        
        # Initialize components with fallbacks
        self.menu_system = AcademicMenuSystem() if AcademicMenuSystem else None
        self.phase1_interface = Phase1TrainingInterface(self.config) if Phase1TrainingInterface else None
        self.phase2_interface = Phase2GenerationInterface(self.config) if Phase2GenerationInterface else None
        self.file_manager = FileManager() if FileManager else None
        self.display = DisplayUtils() if DisplayUtils else None
        
        # GPU availability
        self.gpu_available = gpu_available
        self.torch_module = torch_module
    
    def _safe_display(self, method_name, *args, **kwargs):
        """Safely call display methods with fallback."""
        if self.display and hasattr(self.display, method_name):
            return getattr(self.display, method_name)(*args, **kwargs)
        else:
            # Fallback to simple print
            if method_name == 'show_error':
                print(f"‚ùå {args[0] if args else 'Error'}")
            elif method_name == 'show_warning':
                print(f"‚ö†Ô∏è {args[0] if args else 'Warning'}")
            elif method_name == 'pause_for_user':
                input("Presiona Enter para continuar...")
            else:
                print(f"‚ÑπÔ∏è {args[0] if args else 'Info'}")
    
    def _safe_file_manager(self, method_name, *args, **kwargs):
        """Safely call file manager methods with fallback."""
        if self.file_manager and hasattr(self.file_manager, method_name):
            return getattr(self.file_manager, method_name)(*args, **kwargs)
        else:
            print(f"‚ùå File manager no disponible para {method_name}")
            return None
    
    def run_interactive_mode(self) -> int:
        """Run the main interactive academic interface."""
        if not self.menu_system:
            print("‚ùå Sistema de men√∫s no disponible. Por favor instala las dependencias faltantes.")
            return 1
            
        try:
            while True:
                self.menu_system.show_header()
                choice = self.menu_system.show_main_menu()
                
                if choice == '1':
                    # Phase 1: Intensive Training
                    if not self.phase1_interface:
                        print("‚ùå Interfaz de entrenamiento no disponible.")
                        continue
                        
                    if not self.gpu_available:
                        self._safe_display('show_warning',
                            "GPU no disponible. Se recomienda GPU para entrenamiento eficiente."
                        )
                        
                        # Simple confirmation without InputValidator if not available
                        response = input("¬øContinuar de todas formas? (y/N): ").lower().strip()
                        if response not in ('y', 'yes', 's', 'si'):
                            continue
                    
                    self.phase1_interface.run_intensive_training()
                
                elif choice == '2':
                    # Phase 2: Text Generation
                    if not self.phase2_interface:
                        print("‚ùå Interfaz de generaci√≥n no disponible.")
                        continue
                    self.phase2_interface.run_generation_studio()
                
                elif choice == '3':
                    # View Available Models
                    self._show_available_models()
                
                elif choice == '4':
                    # HOSPITAL - Cirug√≠a de Gates (NEW)
                    self._run_gate_surgery()
                
                elif choice == '5':
                    # AN√ÅLISIS - Gradient Flow Analysis (NEW)
                    self._run_gradient_analysis()
                
                elif choice == '6':
                    # Monitor Training Progress
                    self._monitor_training_progress()
                
                elif choice == '7':
                    # Clean All Models
                    self._clean_all_models()
                
                elif choice == '8':
                    # Test Suite M√≥dulo 2
                    self._run_test_suite()
                
                elif choice == 'A':
                    # Ver Logs y Archivos Generados
                    self._view_logs_and_files()
                
                elif choice == 'B':
                    # Explorar Visualizaciones y Gr√°ficos
                    self._explore_visualizations()
                
                elif choice == 'C':
                    # Attention Mechanism Demo & Validation
                    self._run_attention_demos()
                
                elif choice == 'D':
                    # Dataset Preprocessing Pipeline
                    self._run_dataset_preprocessing()
                
                elif choice == '9':
                    # System Configuration and Status
                    self.menu_system.show_system_status()
                
                elif choice == '0':
                    # Exit
                    self.menu_system.show_exit_message()
                    return 0
                
                else:
                    print("‚ùå Opci√≥n inv√°lida. Por favor selecciona 0-9, A-B.")
                    self.display.pause_for_user()
        
        except KeyboardInterrupt:
            print("\n\nüéØ Sistema interrumpido por usuario")
            self.menu_system.show_exit_message()
            return 0
        except Exception as e:
            self.display.show_error(f"Error cr√≠tico en orchestrator: {e}")
            return 1
    
    def run_direct_training(self, text_file: str, epochs: int, model_name: str) -> int:
        """Run direct training mode (CLI) with mandatory model name."""
        try:
            if not self.gpu_available:
                print("‚ö†Ô∏è GPU no disponible - entrenamiento ser√° lento en CPU")
            
            print(f"üöÄ Modo directo: Entrenando modelo '{model_name}' con {text_file} por {epochs} √©pocas")
            
            # Validate parameters
            if not Path(text_file).exists():
                self.display.show_error(f"Archivo no encontrado: {text_file}")
                return 1
            
            valid, message = self.file_manager.validate_text_file(text_file)
            if not valid:
                self.display.show_error(message)
                return 1
            
            # Import training modules
            from data_processor import TextProcessor
            from model import LSTMTextGenerator, ModelTrainer, ModelManager
            import json
            from datetime import datetime
            
            print("‚úÖ Archivo v√°lido, iniciando entrenamiento...")
            
            # Prepare data
            processor = TextProcessor(
                sequence_length=self.config.model.sequence_length,
                step_size=3  # Fixed step size for sliding window
            )
            
            # Load and prepare multi-corpus text
            X_onehot, y_onehot = processor.prepare_data("corpus", max_length=500_000)
            
            # Convert one-hot to integer encoding for embedding layer
            X = np.argmax(X_onehot, axis=-1)  # Shape: (samples, sequence_length)
            y = np.argmax(y_onehot, axis=-1)  # Shape: (samples,)
            
            # Build model
            model_builder = LSTMTextGenerator(
                vocab_size=processor.vocab_size,
                sequence_length=self.config.model.sequence_length,
                lstm_units=self.config.model.lstm_units[0] if isinstance(self.config.model.lstm_units, list) else self.config.model.lstm_units,
                variational_dropout_rate=self.config.model.dropout_rate
            )
            model = model_builder.build_model()
            
            # Train model - GPU MANDATORY, no CPU fallback
            if not self.gpu_available:
                print("\nüî¥ SISTEMA TERMINADO: GPU es obligatoria para este proyecto acad√©mico")
                import sys
                sys.exit(1)
            
            device = '/GPU:0'  # FIXED: Always GPU, no fallback
            trainer = ModelTrainer(model, device)
            
            history = trainer.train(
                X, y,
                batch_size=self.config.model.batch_size,
                epochs=epochs,
                validation_split=self.config.data.validation_split
            )
            
            # Save model and metadata with user-provided name
            model_filename = f"{model_name}.keras"
            model_path = self.file_manager.models_dir / model_filename
            
            ModelManager.save_model(model, str(model_path))
            
            # Save metadata
            metadata = {
                'model_name': model_name,
                'model_file': model_filename,
                'training_file': text_file,
                'epochs': epochs,
                'final_epoch': len(history.history['loss']),
                'final_loss': float(history.history['loss'][-1]),
                'final_accuracy': float(history.history['accuracy'][-1]),
                'vocab_size': processor.vocab_size,
                'sequence_length': self.config.model.sequence_length,
                'lstm_units': self.config.model.lstm_units,
                'dropout_rate': self.config.model.dropout_rate,
                'batch_size': self.config.model.batch_size,
                'char_to_idx': processor.token_to_idx,  # Legacy name kept for compatibility
                'idx_to_char': processor.idx_to_token,  # Legacy name kept for compatibility
                'token_to_idx': processor.token_to_idx,
                'idx_to_token': processor.idx_to_token,
                'training_start_time': datetime.now().isoformat(),
                'training_end_time': datetime.now().isoformat(),
                'gpu_used': self.gpu_available
            }
            
            metadata_path = self.file_manager.models_dir / f"{model_name}_metadata.json"
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            print(f"‚úÖ Entrenamiento completado exitosamente")
            print(f"üè∑Ô∏è  Modelo '{model_name}' guardado")
            print(f"üíæ Archivo: {model_path}")
            print(f"üìã Metadata: {metadata_path}")
            print(f"üé® Ahora puedes usar: python robo_poet.py --generate {model_filename}")
            
            return 0
            
        except Exception as e:
            self.display.show_error(f"Error en entrenamiento directo: {e}")
            return 1
    
    def run_corpus_training(self, epochs: int, model_name: str) -> int:
        """
        Run multi-corpus training mode - automatically uses all texts in corpus/.
        This is the new preferred method that replaces single-file training.
        """
        return self.run_direct_training("corpus", epochs, model_name)
    
    def run_direct_generation(self, model_path: str, seed: str = "The power of", 
                             temperature: float = 0.8, length: int = 200) -> int:
        """Run direct generation mode (CLI)."""
        try:
            if not Path(model_path).exists():
                self.display.show_error(f"Modelo no encontrado: {model_path}")
                return 1
            
            print(f"üé® Generando texto con modelo: {Path(model_path).name}")
            
            # Import generation modules
            from model import ModelManager
            from data_processor import TextGenerator
            import json
            
            # Load model
            model_manager = ModelManager()
            model = model_manager.load_model(model_path)
            
            if not model:
                self.display.show_error("No se pudo cargar el modelo")
                return 1
            
            # Load metadata
            metadata_path = Path(model_path).parent / (Path(model_path).stem + '_metadata.json')
            if metadata_path.exists():
                with open(metadata_path) as f:
                    metadata = json.load(f)
                # Support both old and new naming conventions
                char_to_idx = metadata.get('token_to_idx', metadata.get('char_to_idx', {}))
                raw_idx_to_char = metadata.get('idx_to_token', metadata.get('idx_to_char', {}))
                idx_to_char = {int(k): v for k, v in raw_idx_to_char.items()}
            else:
                self.display.show_error("Metadata no encontrada - no se puede generar texto")
                return 1
            
            # Generate text
            generator = TextGenerator(model, char_to_idx, idx_to_char, tokenization='word')
            result = generator.generate(seed, length, temperature)
            
            # Display result
            self.display.format_generation_result(
                result, seed, temperature, length, 0, Path(model_path).name
            )
            
            return 0
            
        except Exception as e:
            self.display.show_error(f"Error en generaci√≥n directa: {e}")
            return 1
    
    def _show_available_models(self) -> None:
        """Show available models with enhanced information."""
        print("\nüìä MODELOS DISPONIBLES")
        print("=" * 60)
        
        models = self.file_manager.list_available_models_enhanced()
        
        if not models:
            print("üì≠ No hay modelos entrenados disponibles")
            print("üí° Ejecuta FASE 1: Entrenamiento Intensivo para crear modelos")
        else:
            print(f"üìà Total de modelos: {len(models)}")
            print()
            
            for i, model_info in enumerate(models, 1):
                print(f"{i}. ", end="")
                self.display.format_model_info(model_info)
        
        self.display.pause_for_user()
    
    def _monitor_training_progress(self) -> None:
        """Monitor training progress (placeholder for advanced monitoring)."""
        print("\nüìà MONITOREO DE PROGRESO DE ENTRENAMIENTO")
        print("=" * 60)
        print("üîç Buscando entrenamientos activos...")
        
        # Check for active TensorBoard logs
        if self.file_manager.logs_dir.exists():
            log_files = list(self.file_manager.logs_dir.glob("*"))
            if log_files:
                print(f"üìä Encontrados {len(log_files)} logs de entrenamiento")
                print("üí° Para monitoreo en tiempo real:")
                print("   tensorboard --logdir logs --port 6006")
                print("   Luego abre: http://localhost:6006")
            else:
                print("üì≠ No hay logs de entrenamiento disponibles")
        else:
            print("üì≠ Directorio de logs no encontrado")
        
        print("\nüí° HERRAMIENTAS DE MONITOREO:")
        print("   üñ•Ô∏è GPU: nvidia-smi")
        print("   üìä TensorBoard: tensorboard --logdir logs")
        print("   üîÑ Tiempo real: watch nvidia-smi")
        
        self.display.pause_for_user()
    
    def _run_gate_surgery(self) -> None:
        """
        üè• HOSPITAL - Ejecutar cirug√≠a de emergencia en modelo con gates saturados
        """
        print("\nüè• HOSPITAL - CIRUG√çA DE GATES LSTM")
        print("=" * 50)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("üì≠ No hay modelos disponibles para cirug√≠a")
            self.display.pause_for_user()
            return
        
        print("üìä Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            print(f"   {i}. {model_name}")
        
        print("\nüîç Selecciona el modelo a diagnosticar:")
        try:
            choice = input("   N√∫mero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("‚ùå Cirug√≠a cancelada")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nüî¨ Modelo seleccionado: {Path(selected_model).name}")
                print("‚ö†Ô∏è  La cirug√≠a modificar√° permanentemente los gates del modelo")
                
                confirm = input("\n¬øProceder con la cirug√≠a? (s/N): ").lower().strip()
                
                if confirm in ('s', 'si', 'y', 'yes'):
                    # Ejecutar cirug√≠a
                    from hospital.emergency_gate_surgery import quick_surgery
                    
                    print("\nüö® INICIANDO CIRUG√çA DE EMERGENCIA...")
                    operated_model, report = quick_surgery(selected_model)
                    
                    if operated_model and report:
                        print("\nüéâ CIRUG√çA EXITOSA")
                        print("üìä El modelo fue operado y guardado con prefijo 'operated_'")
                        print("üìã Reporte de cirug√≠a guardado en src/hospital/")
                    else:
                        print("\n‚ùå La cirug√≠a fall√≥")
                else:
                    print("‚ùå Cirug√≠a cancelada")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
        except Exception as e:
            self.display.show_error(f"Error en cirug√≠a: {e}")
        
        self.display.pause_for_user()
    
    def _run_gradient_analysis(self) -> None:
        """
        üî¨ AN√ÅLISIS - Ejecutar an√°lisis profundo de gradient flow
        """
        print("\nüî¨ AN√ÅLISIS PROFUNDO DE MODELOS LSTM")
        print("=" * 60)
        print("üìã MEN√ö DE AN√ÅLISIS DISPONIBLES:")
        print()
        print("üî¨ DIAGN√ìSTICOS DE GRADIENTES:")
        print("1. üìà Gradient Flow Analysis")
        print("   ‚Ä¢ Detecci√≥n de vanishing/exploding gradients") 
        print("   ‚Ä¢ An√°lisis de propagaci√≥n por capas")
        print("   ‚Ä¢ M√©tricas de Pascanu et al. 2013")
        print()
        print("üèîÔ∏è  AN√ÅLISIS DE PAISAJE DE P√âRDIDA:")
        print("2. üéØ Sharp vs Flat Minima Detection")
        print("   ‚Ä¢ An√°lisis de sharpness del m√≠nimo actual")
        print("   ‚Ä¢ Predicci√≥n de capacidad de generalizaci√≥n")
        print("   ‚Ä¢ Visualizaci√≥n de curvatura Hessiana")
        print()
        print("üöÄ AN√ÅLISIS INTEGRAL:")
        print("3. üîç Suite Completa de An√°lisis")
        print("   ‚Ä¢ Combina ambos an√°lisis anteriores")
        print("   ‚Ä¢ Reporte consolidado de diagn√≥stico")
        print("   ‚Ä¢ Recomendaciones integradas")
        print()
        print("üß™ EXPERIMENTOS DE ABLACI√ìN:")
        print("4. ‚öóÔ∏è Ablation Study (Componente Impact)")
        print("   ‚Ä¢ Identifica componentes cr√≠ticos del modelo")
        print("   ‚Ä¢ Compara variantes arquitect√≥nicas")
        print("   ‚Ä¢ Optimizaci√≥n sistem√°tica de hiperpar√°metros")
        print()
        print("=" * 60)
        
        choice = input("üéØ Selecciona an√°lisis (1-4): ").strip()
        
        if choice == "1":
            self._run_gradient_flow_analysis()
        elif choice == "2":
            self._run_minima_analysis()
        elif choice == "3":
            self._run_gradient_flow_analysis()
            print("\n" + "="*50)
            self._run_minima_analysis()
        elif choice == "4":
            self._run_ablation_study()
        else:
            print("‚ùå Opci√≥n inv√°lida")
            self.display.pause_for_user()
    
    def _run_gradient_flow_analysis(self) -> None:
        """Ejecutar an√°lisis de gradient flow espec√≠ficamente."""
        print("\nüìà AN√ÅLISIS DE GRADIENT FLOW")
        print("=" * 50)
        print("üî¨ ENTRADA: Modelo LSTM entrenado")
        print("üìä SALIDA: M√©tricas de gradientes, gr√°ficos y reporte JSON")
        print("‚è±Ô∏è  TIEMPO: ~2-5 minutos seg√∫n n√∫mero de batches")
        print("=" * 50)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("üì≠ No hay modelos disponibles para an√°lisis")
            self.display.pause_for_user()
            return
        
        print("üìä Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            # Marcar modelos operados
            if 'operated' in model_name:
                print(f"   {i}. {model_name} üè• (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nüîç Selecciona el modelo a analizar:")
        try:
            choice = input("   N√∫mero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("‚ùå An√°lisis cancelado")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nüìä Modelo seleccionado: {Path(selected_model).name}")
                
                # Solicitar n√∫mero de batches
                batches_input = input("üìà N√∫mero de batches a analizar (default: 30): ").strip()
                num_batches = int(batches_input) if batches_input else 30
                
                # Ejecutar an√°lisis
                from analysis.gradient_analyzer_lite import GradientAnalyzerLite
                
                print(f"\nüî¨ INICIANDO AN√ÅLISIS ({num_batches} batches)...")
                analyzer = GradientAnalyzerLite(selected_model)
                results = analyzer.run_complete_analysis(num_batches)
                
                if results:
                    print("\nüéâ AN√ÅLISIS DE GRADIENTES COMPLETADO")
                    print("=" * 55)
                    
                    # Mostrar resumen de resultados
                    collapse_info = results.get('collapse_analysis', {})
                    pascanu_info = results.get('pascanu_analysis', {})
                    
                    print("üìä DIAGN√ìSTICO DE GRADIENTES:")
                    print(f"‚îå{'‚îÄ' * 53}‚îê")
                    
                    if collapse_info.get('earliest_collapse', -1) >= 0:
                        print(f"‚îÇ üî¥ Colapso en batch: {collapse_info['earliest_collapse']:<32} ‚îÇ")
                    else:
                        print(f"‚îÇ ‚úÖ Sin colapso detectado{' ' * 32} ‚îÇ")
                    
                    vanishing_status = "‚ö†Ô∏è  S√ç" if pascanu_info.get('has_vanishing') else "‚úÖ NO"
                    exploding_status = "‚ö†Ô∏è  S√ç" if pascanu_info.get('has_exploding') else "‚úÖ NO"
                    
                    print(f"‚îÇ üìâ Vanishing gradients: {vanishing_status:<28} ‚îÇ")
                    print(f"‚îÇ üìà Exploding gradients: {exploding_status:<28} ‚îÇ")
                    print(f"‚îî{'‚îÄ' * 53}‚îò")
                    
                    # Status general
                    if not pascanu_info.get('has_vanishing') and not pascanu_info.get('has_exploding'):
                        print("\nüéØ ESTADO: Flujo de gradientes ESTABLE - Modelo saludable")
                    else:
                        print("\n‚ö†Ô∏è  ESTADO: Problemas detectados - Considerar ajustes")
                    
                    print(f"\nüìÅ ARCHIVOS GENERADOS:")
                    print(f"   üìä CSV: gradient_tracking_*.csv")
                    print(f"   üìà Visualizaci√≥n: gradient_analysis_*.png")
                    print(f"   üìã Reporte JSON: gradient_analysis_lite_*.json")
                else:
                    print("\n‚ùå El an√°lisis fall√≥")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
        except Exception as e:
            self.display.show_error(f"Error en an√°lisis: {e}")
        
        self.display.pause_for_user()
    
    def _run_minima_analysis(self) -> None:
        """Ejecutar an√°lisis de Sharp vs Flat Minima."""
        print("\nüèîÔ∏è AN√ÅLISIS DE PAISAJE DE P√âRDIDA (SHARP VS FLAT MINIMA)")
        print("=" * 70)
        print("üî¨ ENTRADA: Modelo LSTM entrenado")
        print("üìä SALIDA: Clasificaci√≥n de sharpness, visualizaci√≥n del paisaje")
        print("‚è±Ô∏è  TIEMPO: ~5-15 minutos seg√∫n configuraci√≥n")
        print("üéØ PROP√ìSITO: Predecir capacidad de generalizaci√≥n del modelo")
        print("=" * 70)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("üì≠ No hay modelos disponibles para an√°lisis")
            self.display.pause_for_user()
            return
        
        print("üìä Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            if 'operated' in model_name:
                print(f"   {i}. {model_name} üè• (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nüîç Selecciona el modelo a analizar:")
        try:
            choice = input("   N√∫mero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("‚ùå An√°lisis cancelado")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nüìä Modelo seleccionado: {Path(selected_model).name}")
                print("üî¨ Configurando an√°lisis de paisaje de p√©rdida...")
                
                # Configuraci√≥n de an√°lisis
                print("\n‚öôÔ∏è CONFIGURACI√ìN DEL AN√ÅLISIS:")
                print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
                print("‚îÇ 1. üöÄ R√ÅPIDO    ‚îÇ 20 direcciones ‚îÇ 30 muestras  ‚îÇ ~2-3 min ‚îÇ")
                print("‚îÇ 2. üìä EST√ÅNDAR  ‚îÇ 50 direcciones ‚îÇ 100 muestras ‚îÇ ~5-8 min ‚îÇ") 
                print("‚îÇ 3. üî¨ PROFUNDO  ‚îÇ 100 direcciones‚îÇ 200 muestras ‚îÇ ~10-15min‚îÇ")
                print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
                print("üí° M√°s direcciones = mayor precisi√≥n en detecci√≥n de sharpness")
                
                config_choice = input("Selecciona configuraci√≥n (1-3, default: 2): ").strip()
                
                # Configurar par√°metros seg√∫n elecci√≥n
                if config_choice == "1":
                    config = {
                        'num_directions': 20,
                        'num_samples': 30,
                        'hessian_samples': 10,
                        'save_plots': True
                    }
                    print("‚ö° Configuraci√≥n r√°pida seleccionada")
                elif config_choice == "3":
                    config = {
                        'num_directions': 100,
                        'num_samples': 200,
                        'hessian_samples': 50,
                        'save_plots': True
                    }
                    print("üî¨ Configuraci√≥n profunda seleccionada")
                else:
                    config = {
                        'num_directions': 50,
                        'num_samples': 100,
                        'hessian_samples': 20,
                        'save_plots': True
                    }
                    print("üìä Configuraci√≥n est√°ndar seleccionada")
                
                # Ejecutar an√°lisis
                from analysis.minima_analyzer import analyze_model_sharpness
                
                print(f"\nüî¨ INICIANDO AN√ÅLISIS DE SHARPNESS...")
                print("‚è≥ Este proceso puede tomar varios minutos...")
                
                try:
                    results = analyze_model_sharpness(selected_model, config=config)
                    
                    if results:
                        print("\nüéâ AN√ÅLISIS DE SHARPNESS COMPLETADO")
                        print("=" * 60)
                        
                        # Mostrar resumen de resultados
                        classification = results.get('sharpness_classification', {})
                        
                        print("üìä RESULTADO DEL AN√ÅLISIS:")
                        print(f"‚îå{'‚îÄ' * 58}‚îê")
                        print(f"‚îÇ üè∑Ô∏è  Categor√≠a: {classification.get('category', 'N/A'):<44} ‚îÇ")
                        print(f"‚îÇ üìà Sharpness: {classification.get('overall_sharpness', 0):<45.4f} ‚îÇ")
                        print(f"‚îî{'‚îÄ' * 58}‚îò")
                        print()
                        print(f"üí° INTERPRETACI√ìN:")
                        print(f"   {classification.get('interpretation', 'N/A')}")
                        
                        # Mostrar recomendaciones
                        recommendations = results.get('recommendations', [])
                        if recommendations:
                            print("\nüí° RECOMENDACIONES:")
                            for rec in recommendations:
                                print(f"   ‚Ä¢ {rec}")
                        
                        # Informaci√≥n de archivos generados
                        viz_path = results.get('visualization_path')
                        if viz_path:
                            print(f"\nüìÅ Archivos generados:")
                            print(f"   üìà Visualizaci√≥n: {viz_path}")
                            print(f"   üìã Reporte JSON: minima_analysis_*.json")
                        
                        # Mostrar m√©tricas t√©cnicas adicionales
                        perturbation = results.get('perturbation_analysis', {})
                        curvature = results.get('curvature_analysis', {})
                        
                        if perturbation:
                            print(f"\nüìä M√âTRICAS T√âCNICAS:")
                            print(f"   üìç Loss baseline: {perturbation.get('baseline_loss', 0):.4f}")
                        
                        if curvature:
                            print(f"   üî¢ Max eigenvalue: {curvature.get('max_eigenvalue', 0):.4f}")
                            print(f"   üìè Condition number: {curvature.get('condition_number', 0):.2f}")
                    else:
                        print("\n‚ùå El an√°lisis de sharpness fall√≥")
                        
                except Exception as e:
                    print(f"\n‚ùå Error durante an√°lisis: {e}")
                    print("üí° Tip: Aseg√∫rate de que el modelo sea compatible")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
        except Exception as e:
            self.display.show_error(f"Error en an√°lisis de minima: {e}")
        
        self.display.pause_for_user()
    
    def _run_ablation_study(self) -> None:
        """Ejecutar experimentos de ablaci√≥n sistem√°tica."""
        print("\nüß™ EXPERIMENTOS DE ABLACI√ìN SISTEM√ÅTICA")
        print("=" * 60)
        print("üî¨ ENTRADA: Modelo LSTM entrenado")
        print("üìä SALIDA: An√°lisis comparativo de componentes")
        print("‚è±Ô∏è  TIEMPO: ~15-30 minutos seg√∫n configuraci√≥n")
        print("üéØ PROP√ìSITO: Identificar componentes cr√≠ticos del modelo")
        print("=" * 60)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("üì≠ No hay modelos disponibles para an√°lisis")
            self.display.pause_for_user()
            return
        
        print("üìä Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            if 'operated' in model_name:
                print(f"   {i}. {model_name} üè• (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nüîç Selecciona el modelo para ablaci√≥n:")
        try:
            choice = input("   N√∫mero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("‚ùå Experimentos cancelados")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nüìä Modelo seleccionado: {Path(selected_model).name}")
                print("üî¨ Configurando experimentos de ablaci√≥n...")
                
                # Selecci√≥n de tipos de experimento
                print("\n‚öôÔ∏è TIPOS DE EXPERIMENTO DISPONIBLES:")
                print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
                print("‚îÇ 1. üìê LSTM Units    ‚îÇ Impacto del tama√±o de capas   ‚îÇ")
                print("‚îÇ 2. üèóÔ∏è  LSTM Layers   ‚îÇ Efecto del n√∫mero de capas    ‚îÇ") 
                print("‚îÇ 3. üíß Dropout Rate  ‚îÇ Influencia de regularizaci√≥n  ‚îÇ")
                print("‚îÇ 4. üìö Embeddings    ‚îÇ Dimensiones de representaci√≥n ‚îÇ")
                print("‚îÇ 5. üîç Completo      ‚îÇ Todos los experimentos        ‚îÇ")
                print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
                
                exp_choice = input("Selecciona tipo de experimento (1-5, default: 1): ").strip()
                
                # Configurar experimentos seg√∫n elecci√≥n
                if exp_choice == "2":
                    experiment_types = ['lstm_layers']
                    print("üèóÔ∏è Experimento: N√∫mero de capas LSTM")
                elif exp_choice == "3":
                    experiment_types = ['dropout_rate']
                    print("üíß Experimento: Dropout rate")
                elif exp_choice == "4":
                    experiment_types = ['embedding_dim']
                    print("üìö Experimento: Dimensiones de embedding")
                elif exp_choice == "5":
                    experiment_types = ['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim']
                    print("üîç Experimento completo: Todos los componentes")
                else:  # Default: lstm_units
                    experiment_types = ['lstm_units']
                    print("üìê Experimento: Tama√±o de unidades LSTM")
                
                # Configurar velocidad del experimento
                print("\n‚ö° CONFIGURACI√ìN DE VELOCIDAD:")
                print("1. üöÄ R√°pido (3 √©pocas, datos sint√©ticos) - ~5 min")
                print("2. üìä Est√°ndar (5 √©pocas, datos sint√©ticos) - ~15 min")
                print("3. üî¨ Completo (10 √©pocas, datos reales si disponible) - ~30+ min")
                
                speed_choice = input("Selecciona velocidad (1-3, default: 1): ").strip()
                
                if speed_choice == "2":
                    epochs = 5
                    quick_mode = True
                    print("üìä Configuraci√≥n est√°ndar seleccionada")
                elif speed_choice == "3":
                    epochs = 10
                    quick_mode = False
                    print("üî¨ Configuraci√≥n completa seleccionada")
                else:
                    epochs = 3
                    quick_mode = True
                    print("üöÄ Configuraci√≥n r√°pida seleccionada")
                
                # Ejecutar experimentos
                from analysis.ablation_analyzer import AblationExperimentRunner
                
                print(f"\nüß™ INICIANDO EXPERIMENTOS DE ABLACI√ìN...")
                print("‚è≥ Este proceso puede tomar tiempo...")
                print("üìä Se entrenar√°n m√∫ltiples variantes del modelo...")
                
                try:
                    runner = AblationExperimentRunner(selected_model)
                    results = runner.run_ablation_study(
                        experiment_types=experiment_types,
                        epochs=epochs,
                        quick_mode=quick_mode
                    )
                    
                    if results and not results.get('error'):
                        print("\nüéâ EXPERIMENTOS DE ABLACI√ìN COMPLETADOS")
                        print("=" * 50)
                        
                        # Mostrar resultados principales
                        comparative = results.get('comparative_analysis', {})
                        best_overall = comparative.get('best_overall', {})
                        
                        if 'by_perplexity' in best_overall:
                            best = best_overall['by_perplexity']
                            print("üèÜ MEJOR CONFIGURACI√ìN ENCONTRADA:")
                            print(f"‚îå{'‚îÄ' * 48}‚îê")
                            print(f"‚îÇ Experimento: {best['experiment']:<32} ‚îÇ")
                            print(f"‚îÇ Variante: {best['variant']:<35} ‚îÇ")
                            print(f"‚îÇ Perplexity: {best['metrics']['perplexity']:<31.2f} ‚îÇ")
                            print(f"‚îÇ Par√°metros: {best['metrics']['total_params']:<29,} ‚îÇ")
                            print(f"‚îî{'‚îÄ' * 48}‚îò")
                        
                        # Mostrar insights de ablaci√≥n
                        insights = comparative.get('ablation_insights', {})
                        if insights:
                            print("\nüí° INSIGHTS DE COMPONENTES:")
                            for component, data in insights.items():
                                impact = data['impact_score']
                                if impact > 0.1:
                                    status = "üî¥ CR√çTICO"
                                elif impact > 0.05:
                                    status = "üü° IMPORTANTE"
                                else:
                                    status = "üü¢ MENOR"
                                
                                print(f"   {component}: {status} (impacto: {impact:.3f})")
                        
                        # Generar visualizaci√≥n
                        viz_path = runner.generate_visualization(results)
                        
                        print(f"\nüìÅ ARCHIVOS GENERADOS:")
                        print(f"   üìä Visualizaci√≥n: {viz_path}")
                        print(f"   üìã Reporte JSON: {results.get('results_path', 'N/A')}")
                        
                        print("\nüéØ RECOMENDACI√ìN FINAL:")
                        if best_overall.get('by_efficiency'):
                            eff_best = best_overall['by_efficiency']
                            print(f"   Para mejor eficiencia: {eff_best['variant']}")
                        
                    else:
                        error = results.get('error', 'Error desconocido')
                        print(f"\n‚ùå Experimentos fallaron: {error}")
                        
                except Exception as e:
                    print(f"\n‚ùå Error durante experimentos: {e}")
                    print("üí° Tip: Aseg√∫rate de que el modelo sea compatible")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
        except Exception as e:
            self.display.show_error(f"Error en experimentos de ablaci√≥n: {e}")
        
        self.display.pause_for_user()
    
    def _run_test_suite(self) -> None:
        """Ejecutar suite de tests del M√≥dulo 2."""
        print("\nüß™ SUITE DE TESTS M√ìDULO 2")
        print("=" * 60)
        print("üéØ SISTEMA COMPLETO DE VALIDACI√ìN Y DEMOSTRACI√ìN")
        print("=" * 60)
        print()
        print("Esta suite ejecutar√° autom√°ticamente:")
        print("‚Ä¢ üìö Entrenamiento de modelo de prueba (3 √©pocas)")
        print("‚Ä¢ üìà An√°lisis completo de gradientes")  
        print("‚Ä¢ üèîÔ∏è An√°lisis del paisaje de p√©rdida")
        print("‚Ä¢ üß™ Experimentos de ablaci√≥n")
        print("‚Ä¢ üè• Cirug√≠a de emergencia de gates")
        print("‚Ä¢ üìã Generaci√≥n de reportes consolidados")
        print()
        print("üïí Tiempo estimado: 10-20 minutos")
        print("üìÅ Se generar√°n logs y reportes detallados")
        print()
        
        # Men√∫ de opciones de testing
        print("üìã OPCIONES DE TESTING DISPONIBLES:")
        print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
        print("‚îÇ 1. üöÄ Demo R√°pido     ‚îÇ Tests b√°sicos (~5 min)     ‚îÇ")
        print("‚îÇ 2. üî¨ Validaci√≥n Full ‚îÇ Todos los tests (~20 min)  ‚îÇ")  
        print("‚îÇ 3. üéØ Tests Selectivos‚îÇ Elegir tests espec√≠ficos   ‚îÇ")
        print("‚îÇ 4. üìä Tests por Bloque‚îÇ Ejecutar por categor√≠as    ‚îÇ")
        print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
        print()
        
        choice = input("Selecciona modalidad (1-4): ").strip()
        
        if choice == "1":
            self._run_quick_demo()
        elif choice == "2":
            self._run_full_validation()
        elif choice == "3":
            self._run_selective_tests()
        elif choice == "4":
            self._run_block_tests()
        else:
            print("‚ùå Opci√≥n inv√°lida")
            self.display.pause_for_user()
            return
    
    def _run_quick_demo(self) -> None:
        """Ejecutar demo r√°pido del sistema."""
        print("\nüöÄ DEMO R√ÅPIDO - VALIDACI√ìN B√ÅSICA")
        print("=" * 50)
        print("Ejecutando: Entrenamiento ‚Üí Gradientes ‚Üí Cirug√≠a")
        print("‚è±Ô∏è Tiempo estimado: 5 minutos")
        print()
        
        confirm = input("¬øProceder con demo r√°pido? (s/N): ").lower().strip()
        
        if confirm in ('s', 'si', 'y', 'yes'):
            try:
                from testing.module2_test_suite import run_quick_demo
                
                print("\nüé¨ INICIANDO DEMO...")
                results = run_quick_demo()
                
                self._show_test_results(results, "Demo R√°pido")
                
            except Exception as e:
                print(f"\n‚ùå Error en demo: {e}")
        else:
            print("‚ùå Demo cancelado")
        
        self.display.pause_for_user()
    
    def _run_full_validation(self) -> None:
        """Ejecutar validaci√≥n completa del sistema."""
        print("\nüî¨ VALIDACI√ìN COMPLETA - TODOS LOS COMPONENTES")
        print("=" * 60)
        print("Ejecutando TODOS los tests del M√≥dulo 2:")
        print("‚Ä¢ Entrenamiento + An√°lisis + Ablaci√≥n + Cirug√≠a + Reportes")
        print("‚è±Ô∏è Tiempo estimado: 15-25 minutos")
        print()
        
        confirm = input("¬øProceder con validaci√≥n completa? (s/N): ").lower().strip()
        
        if confirm in ('s', 'si', 'y', 'yes'):
            try:
                from testing.module2_test_suite import run_full_validation
                
                print("\nüî¨ INICIANDO VALIDACI√ìN COMPLETA...")
                results = run_full_validation()
                
                self._show_test_results(results, "Validaci√≥n Completa")
                
            except Exception as e:
                print(f"\n‚ùå Error en validaci√≥n: {e}")
        else:
            print("‚ùå Validaci√≥n cancelada")
        
        self.display.pause_for_user()
    
    def _run_selective_tests(self) -> None:
        """Ejecutar tests espec√≠ficos seleccionados por el usuario."""
        print("\nüéØ TESTS SELECTIVOS - SELECCI√ìN PERSONALIZADA")
        print("=" * 55)
        
        available_tests = [
            ('training', 'üìö Entrenamiento de Modelo'),
            ('gradient_analysis', 'üìà An√°lisis de Gradientes'),
            ('minima_analysis', 'üèîÔ∏è An√°lisis de Minima'),
            ('ablation_experiments', 'üß™ Experimentos de Ablaci√≥n'),
            ('emergency_surgery', 'üè• Cirug√≠a de Emergencia'),
            ('report_generation', 'üìã Generaci√≥n de Reportes')
        ]
        
        print("Selecciona los tests a ejecutar (n√∫meros separados por comas):")
        for i, (test_key, test_name) in enumerate(available_tests, 1):
            print(f"{i}. {test_name}")
        
        selection = input("\nSelecci√≥n (ej: 1,2,5): ").strip()
        
        try:
            selected_indices = [int(x.strip()) for x in selection.split(',')]
            selected_tests = [available_tests[i-1][0] for i in selected_indices 
                            if 1 <= i <= len(available_tests)]
            
            if selected_tests:
                print(f"\n‚úÖ Tests seleccionados: {len(selected_tests)}")
                for test_key in selected_tests:
                    test_name = dict(available_tests)[test_key]
                    print(f"   ‚Ä¢ {test_name}")
                
                confirm = input("\n¬øEjecutar tests seleccionados? (s/N): ").lower().strip()
                
                if confirm in ('s', 'si', 'y', 'yes'):
                    from testing.module2_test_suite import run_selected_tests
                    
                    print("\nüéØ EJECUTANDO TESTS SELECCIONADOS...")
                    results = run_selected_tests(selected_tests)
                    
                    self._show_test_results(results, "Tests Selectivos")
                else:
                    print("‚ùå Ejecuci√≥n cancelada")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Formato de selecci√≥n inv√°lido")
        except Exception as e:
            print(f"‚ùå Error ejecutando tests: {e}")
        
        self.display.pause_for_user()
    
    def _run_block_tests(self) -> None:
        """Ejecutar tests organizados por bloques funcionales."""
        print("\nüìä TESTS POR BLOQUES - CATEGOR√çAS FUNCIONALES")
        print("=" * 55)
        
        test_blocks = {
            'core': {
                'name': 'üéØ CORE (Entrenamiento + Cirug√≠a)',
                'tests': ['training', 'emergency_surgery'],
                'description': 'Funcionalidades b√°sicas del sistema'
            },
            'analysis': {
                'name': 'üî¨ AN√ÅLISIS (Gradientes + Minima)',
                'tests': ['gradient_analysis', 'minima_analysis'],
                'description': 'Suite de an√°lisis profundo'
            },
            'advanced': {
                'name': 'üß™ AVANZADO (Ablaci√≥n + Reportes)',
                'tests': ['ablation_experiments', 'report_generation'],
                'description': 'Funcionalidades experimentales'
            }
        }
        
        print("Selecciona bloque de tests:")
        for i, (block_key, block_info) in enumerate(test_blocks.items(), 1):
            print(f"{i}. {block_info['name']}")
            print(f"   {block_info['description']}")
            print(f"   Tests: {len(block_info['tests'])}")
        
        choice = input("\nSelecciona bloque (1-3): ").strip()
        
        try:
            if choice == "1":
                selected_block = test_blocks['core']
            elif choice == "2":
                selected_block = test_blocks['analysis']
            elif choice == "3":
                selected_block = test_blocks['advanced']
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                self.display.pause_for_user()
                return
            
            print(f"\n‚úÖ Bloque seleccionado: {selected_block['name']}")
            print(f"üìã Tests incluidos: {len(selected_block['tests'])}")
            
            confirm = input("¬øEjecutar este bloque? (s/N): ").lower().strip()
            
            if confirm in ('s', 'si', 'y', 'yes'):
                from testing.module2_test_suite import run_selected_tests
                
                print(f"\nüìä EJECUTANDO BLOQUE: {selected_block['name']}")
                results = run_selected_tests(selected_block['tests'])
                
                self._show_test_results(results, f"Bloque {selected_block['name']}")
            else:
                print("‚ùå Ejecuci√≥n cancelada")
                
        except Exception as e:
            print(f"‚ùå Error ejecutando bloque: {e}")
        
        self.display.pause_for_user()
    
    def _show_test_results(self, results: Dict, test_type: str) -> None:
        """Mostrar resultados consolidados de los tests."""
        print(f"\nüéâ {test_type.upper()} COMPLETADO")
        print("=" * 60)
        
        if results.get('success'):
            stats = results.get('summary_statistics', {})
            print(f"‚úÖ √âXITO TOTAL")
            print(f"üìä Tests ejecutados: {stats.get('successful_tests', 0)}/{stats.get('total_tests', 0)}")
            print(f"‚è±Ô∏è Tiempo total: {stats.get('total_execution_time', 0):.2f} segundos")
            print(f"üìà Tasa de √©xito: {stats.get('success_rate', 0):.1%}")
            
            # Mostrar resultados individuales destacados
            individual_results = results.get('individual_test_results', {})
            
            if 'training' in individual_results:
                training = individual_results['training']
                if training.get('status') == 'SUCCESS':
                    print(f"\nüéØ MODELO ENTRENADO:")
                    print(f"   Par√°metros: {training.get('parameters', 'N/A'):,}")
                    print(f"   √âpocas: {training.get('epochs_trained', 'N/A')}")
            
            if 'gradient_analysis' in individual_results:
                gradient = individual_results['gradient_analysis']
                if gradient.get('status') == 'SUCCESS':
                    print(f"\nüìà AN√ÅLISIS DE GRADIENTES:")
                    vanishing = "S√≠" if gradient.get('has_vanishing') else "No"
                    exploding = "S√≠" if gradient.get('has_exploding') else "No"
                    print(f"   Vanishing: {vanishing}")
                    print(f"   Exploding: {exploding}")
            
            if 'emergency_surgery' in individual_results:
                surgery = individual_results['emergency_surgery']
                if surgery.get('status') == 'SUCCESS':
                    success = "Exitosa" if surgery.get('surgery_successful') else "Fallo"
                    print(f"\nüè• CIRUG√çA: {success}")
            
        else:
            print(f"‚ùå ALGUNOS TESTS FALLARON")
            failed_tests = [name for name, result in results.get('individual_test_results', {}).items() 
                          if result.get('status') != 'SUCCESS']
            print(f"üìã Tests fallidos: {', '.join(failed_tests)}")
        
        # Informaci√≥n de archivos generados
        metadata = results.get('test_suite_metadata', {})
        log_file = metadata.get('log_file')
        if log_file:
            print(f"\nüìÅ ARCHIVOS GENERADOS:")
            print(f"   üìù Log detallado: {log_file}")
            print(f"   üìä Reportes JSON/TXT en directorio actual")
        
        print("\nüí° Los reportes contienen an√°lisis detallado de todos los tests")
    
    def _view_logs_and_files(self) -> None:
        """Ver logs y archivos generados por el sistema."""
        print("\nüìù EXPLORADOR DE LOGS Y ARCHIVOS GENERADOS")
        print("=" * 60)
        
        try:
            from utils.file_viewer import FileViewer, LogInspector
            
            viewer = FileViewer()
            inspector = LogInspector()
            
            # Mostrar resumen de archivos
            summary = viewer.display_file_summary()
            print(summary)
            
            print("\nüìã OPCIONES DE VISUALIZACI√ìN:")
            print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
            print("‚îÇ 1. üìÑ Ver log m√°s reciente                     ‚îÇ")
            print("‚îÇ 2. üìä Inspeccionar reporte espec√≠fico          ‚îÇ")
            print("‚îÇ 3. üîç Buscar por tipo de archivo              ‚îÇ")
            print("‚îÇ 4. üìà Resumen de todos los logs               ‚îÇ")
            print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
            print()
            
            choice = input("Selecciona opci√≥n (1-4): ").strip()
            
            if choice == "1":
                self._view_latest_log(inspector)
            elif choice == "2":
                self._inspect_specific_report(viewer)
            elif choice == "3":
                self._browse_by_file_type(viewer)
            elif choice == "4":
                self._show_logs_summary(inspector)
            else:
                print("‚ùå Opci√≥n inv√°lida")
                
        except ImportError:
            print("‚ùå Sistema de visualizaci√≥n no disponible")
            print("üí° Instala las dependencias necesarias")
        except Exception as e:
            print(f"‚ùå Error accediendo archivos: {e}")
        
        self.display.pause_for_user()
    
    def _view_latest_log(self, inspector: 'LogInspector') -> None:
        """Ver el log m√°s reciente."""
        print("\nüìÑ LOG M√ÅS RECIENTE")
        print("-" * 40)
        
        latest_logs = inspector.find_latest_logs()
        
        if not latest_logs:
            print("üì≠ No se encontraron logs")
            return
        
        latest = latest_logs[0]
        print(f"üìù Archivo: {latest['name']}")
        print(f"üïí Fecha: {latest['modified_human']}")
        print(f"üìè Tama√±o: {latest['size_human']}")
        
        if 'log_type' in latest:
            print(f"üè∑Ô∏è Tipo: {latest['log_type']}")
        
        print("\n" + "="*50)
        
        log_data = inspector.viewer.read_log_file(latest['path'], tail_lines=50)
        
        if log_data['success']:
            print("üìã √öLTIMAS 50 L√çNEAS:")
            print("-" * 30)
            print(log_data['content'])
            
            analysis = log_data['analysis']
            print(f"\nüìä ESTAD√çSTICAS:")
            print(f"   Total l√≠neas: {analysis['total_lines']}")
            print(f"   ‚ùå Errores: {len(analysis['errors'])}")
            print(f"   ‚ö†Ô∏è  Warnings: {len(analysis['warnings'])}")
            print(f"   ‚úÖ √âxitos: {len(analysis['success'])}")
        else:
            print(f"‚ùå Error leyendo log: {log_data['error']}")
    
    def _inspect_specific_report(self, viewer: 'FileViewer') -> None:
        """Inspeccionar un reporte espec√≠fico."""
        print("\nüìä INSPECTOR DE REPORTES")
        print("-" * 40)
        
        files = viewer.scan_generated_files()
        reports = files.get('reports', [])
        
        if not reports:
            print("üì≠ No se encontraron reportes")
            return
        
        print("üìã Reportes disponibles:")
        for i, report in enumerate(reports[:10], 1):
            report_type = report.get('report_type', 'Unknown')
            print(f"{i}. {report['name']} - {report_type} ({report['modified_human']})")
        
        try:
            selection = input(f"\nSelecciona reporte (1-{min(10, len(reports))}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(reports):
                selected = reports[idx]
                self._show_report_details(selected['path'])
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
    
    def _show_report_details(self, report_path: str) -> None:
        """Mostrar detalles de un reporte."""
        print(f"\nüìä DETALLES DEL REPORTE")
        print("=" * 50)
        
        try:
            if report_path.endswith('.json'):
                with open(report_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Mostrar informaci√≥n estructurada seg√∫n el tipo
                if 'test_suite_metadata' in data:
                    self._show_test_report_details(data)
                elif 'sharpness_classification' in data:
                    self._show_minima_report_details(data)
                elif 'collapse_analysis' in data:
                    self._show_gradient_report_details(data)
                else:
                    # Mostrar JSON gen√©rico
                    import json as json_module
                    print(json_module.dumps(data, indent=2, ensure_ascii=False))
            else:
                # Archivo de texto
                with open(report_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                print(content)
                
        except Exception as e:
            print(f"‚ùå Error leyendo reporte: {e}")
    
    def _show_test_report_details(self, data: Dict) -> None:
        """Mostrar detalles espec√≠ficos de reporte de tests."""
        metadata = data['test_suite_metadata']
        stats = data['summary_statistics']
        
        print("üß™ REPORTE DE TESTS")
        print(f"üïí Ejecutado: {metadata['timestamp']}")
        print(f"‚è±Ô∏è Duraci√≥n: {stats['total_execution_time']:.2f}s")
        print(f"üìä Tests: {stats['successful_tests']}/{stats['total_tests']}")
        print(f"üìà √âxito: {stats['success_rate']:.1%}")
        
        print(f"\nüìã RESULTADOS INDIVIDUALES:")
        for test_name, result in data['individual_test_results'].items():
            status = "‚úÖ" if result['status'] == 'SUCCESS' else "‚ùå"
            print(f"  {status} {test_name.replace('_', ' ').title()}")
            
            if result['status'] == 'SUCCESS' and 'total_time' in result:
                print(f"      ‚è±Ô∏è {result['total_time']:.2f}s")
    
    def _show_minima_report_details(self, data: Dict) -> None:
        """Mostrar detalles espec√≠ficos de an√°lisis de minima."""
        classification = data['sharpness_classification']
        
        print("üèîÔ∏è AN√ÅLISIS DE PAISAJE DE P√âRDIDA")
        print(f"üè∑Ô∏è Categor√≠a: {classification['category']}")
        print(f"üìà Sharpness: {classification['overall_sharpness']:.4f}")
        print(f"üí° {classification['interpretation']}")
        
        if 'recommendations' in data:
            print(f"\nüí° RECOMENDACIONES:")
            for rec in data['recommendations']:
                print(f"  ‚Ä¢ {rec}")
    
    def _show_gradient_report_details(self, data: Dict) -> None:
        """Mostrar detalles espec√≠ficos de an√°lisis de gradientes."""
        collapse = data.get('collapse_analysis', {})
        pascanu = data.get('pascanu_analysis', {})
        
        print("üìà AN√ÅLISIS DE GRADIENTES")
        print(f"üìä Batches analizados: {data['analysis_metadata']['batches_analyzed']}")
        print(f"‚è±Ô∏è Duraci√≥n: {data['analysis_metadata']['duration_minutes']:.2f} min")
        
        print(f"\nüìâ DIAGN√ìSTICO:")
        print(f"  Vanishing: {'S√≠' if pascanu.get('has_vanishing') else 'No'}")
        print(f"  Exploding: {'S√≠' if pascanu.get('has_exploding') else 'No'}")
        
        if collapse.get('earliest_collapse', -1) >= 0:
            print(f"  üî¥ Colapso en batch: {collapse['earliest_collapse']}")
    
    def _browse_by_file_type(self, viewer: 'FileViewer') -> None:
        """Navegar archivos por tipo."""
        print("\nüîç NAVEGADOR POR TIPO DE ARCHIVO")
        print("-" * 40)
        
        files = viewer.scan_generated_files()
        
        print("üìÇ Categor√≠as disponibles:")
        categories = list(files.keys())
        for i, category in enumerate(categories, 1):
            count = len(files[category])
            category_display = {
                'logs': 'üìù Logs',
                'reports': 'üìä Reportes', 
                'visualizations': 'üìà Visualizaciones',
                'models': 'üß† Modelos'
            }.get(category, category)
            
            print(f"{i}. {category_display} ({count} archivos)")
        
        try:
            selection = input(f"\nSelecciona categor√≠a (1-{len(categories)}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(categories):
                selected_category = categories[idx]
                self._show_category_files(files[selected_category], selected_category)
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
    
    def _show_category_files(self, file_list: List[Dict], category: str) -> None:
        """Mostrar archivos de una categor√≠a espec√≠fica."""
        category_display = {
            'logs': 'üìù LOGS',
            'reports': 'üìä REPORTES', 
            'visualizations': 'üìà VISUALIZACIONES',
            'models': 'üß† MODELOS'
        }.get(category, category.upper())
        
        print(f"\n{category_display}")
        print("=" * 50)
        
        if not file_list:
            print("üì≠ No hay archivos en esta categor√≠a")
            return
        
        for i, file_info in enumerate(file_list, 1):
            print(f"{i}. üìÑ {file_info['name']}")
            print(f"   üìè {file_info['size_human']} - üïí {file_info['modified_human']}")
            
            # Informaci√≥n espec√≠fica por tipo
            if category == 'logs' and 'log_type' in file_info:
                print(f"   üè∑Ô∏è {file_info['log_type']}")
            elif category == 'reports' and 'report_type' in file_info:
                print(f"   üìä {file_info['report_type']}")
            elif category == 'visualizations' and 'viz_type' in file_info:
                print(f"   üìà {file_info['viz_type']}")
            elif category == 'models' and 'model_type' in file_info:
                print(f"   üß† {file_info['model_type']}")
            
            print()
    
    def _show_logs_summary(self, inspector: 'LogInspector') -> None:
        """Mostrar resumen de todos los logs."""
        print("\nüìà RESUMEN DE LOGS DEL SISTEMA")
        print("=" * 50)
        
        recent_logs = inspector.find_latest_logs()
        
        if not recent_logs:
            print("üì≠ No se encontraron logs")
            return
        
        total_errors = 0
        total_warnings = 0
        total_success = 0
        
        print("üìä LOGS RECIENTES (m√°ximo 10):")
        print("-" * 40)
        
        for log_info in recent_logs:
            print(f"üìù {log_info['name']}")
            print(f"   üïí {log_info['modified_human']}")
            
            if 'errors' in log_info:
                errors = log_info['errors']
                warnings = log_info.get('warnings', 0)
                success = log_info.get('success_markers', 0)
                
                print(f"   üìä ‚ùå {errors} | ‚ö†Ô∏è {warnings} | ‚úÖ {success}")
                
                total_errors += errors
                total_warnings += warnings  
                total_success += success
            
            print()
        
        print("üìà ESTAD√çSTICAS TOTALES:")
        print(f"   ‚ùå Total errores: {total_errors}")
        print(f"   ‚ö†Ô∏è Total warnings: {total_warnings}")
        print(f"   ‚úÖ Total √©xitos: {total_success}")
        
        if total_errors == 0:
            print("\nüéâ ¬°Sistema funcionando sin errores!")
        elif total_errors < total_success:
            print(f"\n‚ö†Ô∏è Sistema mayormente estable ({total_success-total_errors} m√°s √©xitos que errores)")
        else:
            print(f"\nüî¥ Atenci√≥n: {total_errors} errores detectados")
    
    def _explore_visualizations(self) -> None:
        """Explorar visualizaciones y gr√°ficos generados."""
        print("\nüìà EXPLORADOR DE VISUALIZACIONES Y GR√ÅFICOS")
        print("=" * 60)
        
        try:
            from utils.file_viewer import FileViewer
            
            viewer = FileViewer()
            files = viewer.scan_generated_files()
            visualizations = files.get('visualizations', [])
            
            if not visualizations:
                print("üì≠ No se encontraron visualizaciones")
                print("üí° Ejecuta an√°lisis para generar gr√°ficos:")
                print("   ‚Ä¢ python robo_poet.py --analyze modelo.keras")
                print("   ‚Ä¢ python robo_poet.py --minima modelo.keras")
                print("   ‚Ä¢ python robo_poet.py --test quick")
                self.display.pause_for_user()
                return
            
            print(f"üìä VISUALIZACIONES DISPONIBLES ({len(visualizations)}):")
            print("=" * 50)
            
            for i, viz in enumerate(visualizations, 1):
                viz_type = viz.get('viz_type', 'Unknown')
                print(f"{i}. üìà {viz['name']}")
                print(f"   üè∑Ô∏è Tipo: {viz_type}")
                print(f"   üìè {viz['size_human']} - üïí {viz['modified_human']}")
                print()
            
            print("üìã OPCIONES:")
            print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
            print("‚îÇ 1. üìÑ Ver informaci√≥n detallada de gr√°fico     ‚îÇ")
            print("‚îÇ 2. üóÇÔ∏è  Organizar por tipo de an√°lisis          ‚îÇ")
            print("‚îÇ 3. üíª Mostrar comandos para abrir im√°genes     ‚îÇ")
            print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
            print()
            
            choice = input("Selecciona opci√≥n (1-3): ").strip()
            
            if choice == "1":
                self._show_visualization_details(visualizations)
            elif choice == "2":
                self._organize_visualizations_by_type(visualizations)
            elif choice == "3":
                self._show_image_open_commands(visualizations)
            else:
                print("‚ùå Opci√≥n inv√°lida")
                
        except ImportError:
            print("‚ùå Sistema de visualizaci√≥n no disponible")
        except Exception as e:
            print(f"‚ùå Error accediendo visualizaciones: {e}")
        
        self.display.pause_for_user()
    
    def _show_visualization_details(self, visualizations: List[Dict]) -> None:
        """Mostrar detalles de una visualizaci√≥n espec√≠fica."""
        print("\nüìÑ DETALLES DE VISUALIZACI√ìN")
        print("-" * 40)
        
        try:
            selection = input(f"Selecciona visualizaci√≥n (1-{len(visualizations)}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(visualizations):
                viz = visualizations[idx]
                
                print(f"üìà ARCHIVO: {viz['name']}")
                print(f"üóÇÔ∏è Ruta: {viz['path']}")
                print(f"üìè Tama√±o: {viz['size_human']}")
                print(f"üïí Creado: {viz['modified_human']}")
                
                # Informaci√≥n espec√≠fica por tipo
                from utils.file_viewer import FileViewer
                viewer = FileViewer()
                viz_info = viewer.get_visualization_info(viz['path'])
                
                if viz_info['success']:
                    print(f"üè∑Ô∏è Tipo: {viz_info.get('type', 'Unknown')}")
                    print(f"üìã Descripci√≥n: {viz_info.get('description', 'N/A')}")
                    
                    if 'contains' in viz_info:
                        print(f"üìä Contiene:")
                        for item in viz_info['contains']:
                            print(f"   ‚Ä¢ {item}")
                
                # Comando para abrir
                print(f"\nüíª COMANDOS PARA ABRIR:")
                if os.name == 'nt':  # Windows
                    print(f"   start {viz['path']}")
                else:  # Linux/Mac
                    print(f"   xdg-open {viz['path']}")
                    print(f"   eog {viz['path']}  # GNOME")
                    print(f"   feh {viz['path']}  # Lightweight")
            else:
                print("‚ùå Selecci√≥n inv√°lida")
                
        except ValueError:
            print("‚ùå Entrada inv√°lida")
    
    def _organize_visualizations_by_type(self, visualizations: List[Dict]) -> None:
        """Organizar visualizaciones por tipo de an√°lisis."""
        print("\nüóÇÔ∏è VISUALIZACIONES POR TIPO")
        print("=" * 50)
        
        # Agrupar por tipo
        by_type = {}
        for viz in visualizations:
            viz_type = viz.get('viz_type', 'Unknown')
            if viz_type not in by_type:
                by_type[viz_type] = []
            by_type[viz_type].append(viz)
        
        for viz_type, viz_list in by_type.items():
            print(f"\nüìà {viz_type.upper()} ({len(viz_list)} archivos):")
            print("-" * 40)
            
            for viz in viz_list:
                print(f"  üìÑ {viz['name']} - {viz['modified_human']}")
    
    def _show_image_open_commands(self, visualizations: List[Dict]) -> None:
        """Mostrar comandos para abrir todas las im√°genes."""
        print("\nüíª COMANDOS PARA ABRIR IM√ÅGENES")
        print("=" * 50)
        
        if os.name == 'nt':  # Windows
            print("ü™ü COMANDOS WINDOWS:")
            for viz in visualizations:
                print(f"start \"{viz['path']}\"")
        else:  # Linux/Mac
            print("üêß COMANDOS LINUX:")
            for viz in visualizations:
                print(f"xdg-open \"{viz['path']}\"")
                
            print(f"\nüñºÔ∏è ABRIR TODAS DE UNA VEZ:")
            paths = ' '.join(f'"{viz["path"]}"' for viz in visualizations)
            print(f"xdg-open {paths}")
    
    def _clean_all_models(self) -> None:
        """Clean all models with enhanced confirmation."""
        print("\nüßπ LIMPIAR TODOS LOS MODELOS")
        print("=" * 50)
        
        models = self.file_manager.list_available_models()
        if not models:
            print("‚úÖ No hay modelos para limpiar")
            self.display.pause_for_user()
            return
        
        print(f"üìä Se encontraron {len(models)} modelos")
        
        # Calculate total size
        total_size = 0
        for model_path in models:
            total_size += Path(model_path).stat().st_size
        
        total_mb = total_size / (1024 * 1024)
        print(f"üíæ Espacio total a liberar: {total_mb:.1f} MB")
        
        self.display.show_warning(
            "Esta acci√≥n eliminar√° PERMANENTEMENTE todos los modelos entrenados.\n"
            "   No podr√°s usar FASE 2 (Generaci√≥n) hasta entrenar nuevos modelos."
        )
        
        confirm = input("\nüóëÔ∏è ¬øConfirmar limpieza? (escribe 'ELIMINAR' para confirmar): ").strip()
        
        if confirm != 'ELIMINAR':
            print("‚ùå Limpieza cancelada")
            self.display.pause_for_user()
            return
        
        # Perform cleanup
        results = self.file_manager.clean_all_models()
        self.display.format_cleanup_results(results)
        self.display.pause_for_user()
    
    def _run_attention_demos(self) -> None:
        """Ejecutar demos y validaci√≥n del mecanismo de atenci√≥n."""
        print("\nüéØ ATTENTION MECHANISM DEMO & VALIDATION")
        print("=" * 60)
        print("üé≠ Target: Beat LSTM baseline (val_loss = 6.5)")
        print("üìê Implementation: Scaled Dot-Product Attention")
        print()
        
        print("üî¨ OPCIONES DISPONIBLES:")
        print("1. üìñ Conceptual Demo (sin dependencias)")
        print("2. üß™ Validation Suite (requiere TensorFlow)")
        print("3. üìã Architecture Documentation")
        print("4. üîô Volver al men√∫ principal")
        print()
        
        try:
            choice = input("üéØ Selecciona una opci√≥n (1-4): ").strip()
            
            if choice == '1':
                print("\nüöÄ Ejecutando demo conceptual...")
                import subprocess
                result = subprocess.run([
                    'python', 'demos/demo_attention_concept.py'
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(result.stdout)
                else:
                    print("‚ö†Ô∏è Demo conceptual no disponible (dependencias faltantes)")
                    print("üí° El demo muestra la arquitectura y validaciones matem√°ticas")
                    
            elif choice == '2':
                print("\nüß™ Ejecutando suite de validaci√≥n...")
                try:
                    import sys
                    sys.path.insert(0, 'src')
                    from attention.attention_validator import AttentionValidator
                    
                    validator = AttentionValidator(sequence_length=128, d_model=256)
                    results = validator.run_full_validation()
                    
                    if results['summary']['overall_status'] == 'PASSED':
                        print("üéâ ¬°Attention mechanism completamente validado!")
                    else:
                        print("‚ö†Ô∏è Validaci√≥n parcial - revisar logs")
                        
                except ImportError:
                    print("‚ùå TensorFlow no disponible")
                    print("üí° Instalar con: pip install tensorflow numpy")
                    
            elif choice == '3':
                print("\nüìö ATTENTION ARCHITECTURE DOCUMENTATION")
                print("=" * 50)
                print("üìÅ Documentaci√≥n disponible:")
                print("   üìñ docs/technical/ATTENTION_IMPLEMENTATION_SUMMARY.md")
                print("   üîß src/attention/scaled_dot_product_attention.py")
                print("   üß™ src/attention/attention_validator.py")
                print()
                print("üéØ Caracter√≠sticas clave:")
                print("   ‚úÖ Pure TensorFlow (no pre-built layers)")
                print("   ‚úÖ Shape assertions y gradient tracking")
                print("   ‚úÖ Causal masking para autoregressive generation")
                print("   ‚úÖ Dropout despu√©s de softmax")
                print("   ‚úÖ Optimizado para sequence_length=128, d_model=256")
                
            elif choice == '4':
                return
            else:
                print("‚ùå Opci√≥n inv√°lida")
                
        except Exception as e:
            print(f"‚ùå Error en attention demos: {e}")
        
        input("\nüìñ Presiona Enter para continuar...")
    
    def _run_dataset_preprocessing(self) -> None:
        """Ejecutar pipeline de preprocesamiento de dataset."""
        print("\nüèóÔ∏è DATASET PREPROCESSING PIPELINE")
        print("=" * 60)
        print("üéØ Objetivo: Unificar corpus disperso para mejor convergencia")
        print("üé≠ Corpus actual: Shakespeare + Alice (4 archivos)")
        print()
        
        print("üîß OPCIONES DE PREPROCESAMIENTO:")
        print("1. üöÄ Ejecutar Pipeline Completo (Recomendado)")
        print("2. üìä Analizar Corpus Actual")
        print("3. üîç Validar Dataset Procesado")
        print("4. üîô Volver al men√∫ principal")
        print()
        
        try:
            choice = input("üéØ Selecciona una opci√≥n (1-4): ").strip()
            
            if choice == '1':
                print("\nüöÄ EJECUTANDO PIPELINE COMPLETO...")
                print("=" * 50)
                
                try:
                    import sys
                    sys.path.insert(0, 'src')
                    from data.dataset_preprocessor import DatasetPreprocessor, PreprocessingConfig
                    
                    # Configuraci√≥n optimizada para Shakespeare & Alice
                    config = PreprocessingConfig(
                        preserve_case=True,
                        preserve_verse_structure=True,
                        max_vocab_size=15000,
                        remove_rare_words=True,
                        rare_word_threshold=2
                    )
                    
                    preprocessor = DatasetPreprocessor(config)
                    result = preprocessor.process_full_pipeline("corpus")
                    
                    if result['success']:
                        print("\nüéâ PIPELINE COMPLETADO EXITOSAMENTE")
                        print(f"üìö Documentos: {result['documents_loaded']}")
                        print(f"üìù Vocabulario: {result['vocabulary_size']:,}")
                        print(f"üìä Corpus: {result['corpus_size']:,} chars")
                        print(f"‚è±Ô∏è Tiempo: {result['processing_time']:.2f}s")
                        print()
                        print("üí° Dataset unificado disponible en data/processed/")
                        print("üöÄ Ahora entrena con: python robo_poet.py --model unified_model")
                    else:
                        print(f"‚ùå Error en pipeline: {result.get('error', 'Unknown')}")
                        
                except ImportError as e:
                    print(f"‚ùå Error de importaci√≥n: {e}")
                    print("üí° Algunos m√≥dulos requieren dependencias adicionales")
                    
            elif choice == '2':
                print("\nüìä AN√ÅLISIS DEL CORPUS ACTUAL")
                print("=" * 50)
                
                from pathlib import Path
                corpus_path = Path("corpus")
                
                if corpus_path.exists():
                    txt_files = list(corpus_path.glob("*.txt"))
                    
                    if txt_files:
                        print(f"‚úÖ Encontrados {len(txt_files)} archivos:")
                        
                        total_size = 0
                        for txt_file in sorted(txt_files):
                            size = txt_file.stat().st_size
                            total_size += size
                            
                            # An√°lisis b√°sico del contenido
                            try:
                                with open(txt_file, 'r', encoding='utf-8') as f:
                                    content = f.read()[:1000]  # Primera muestra
                                
                                word_count = len(content.split())
                                
                                # Detectar tipo
                                if "shakespeare" in txt_file.name.lower() or "hamlet" in txt_file.name.lower():
                                    doc_type = "üé≠ Drama/Poetry"
                                elif "alice" in txt_file.name.lower():
                                    doc_type = "üìö Narrative"
                                else:
                                    doc_type = "üìñ General"
                                
                                print(f"   {doc_type} {txt_file.name}: {size:,} bytes, ~{word_count*10:,} words")
                                
                            except Exception as e:
                                print(f"   ‚ùå {txt_file.name}: Error - {e}")
                        
                        print(f"\nüìà RESUMEN:")
                        print(f"   Total: {total_size:,} bytes ({total_size/1024:.1f} KB)")
                        print(f"   Problema: Archivos dispersos ‚Üí convergencia lenta")
                        print(f"   Soluci√≥n: Unificar con marcadores de documento")
                        
                    else:
                        print("‚ùå No se encontraron archivos .txt en corpus/")
                else:
                    print("‚ùå Directorio corpus/ no encontrado")
                    
            elif choice == '3':
                print("\nüîç VALIDACI√ìN DE DATASET PROCESADO")
                print("=" * 50)
                
                processed_dir = Path("data/processed")
                if processed_dir.exists():
                    files = list(processed_dir.glob("*.txt")) + list(processed_dir.glob("*.json"))
                    
                    if files:
                        print(f"‚úÖ Dataset procesado encontrado: {len(files)} archivos")
                        
                        for file_path in sorted(files):
                            size = file_path.stat().st_size
                            print(f"   üìÑ {file_path.name}: {size:,} bytes")
                        
                        # Verificar splits
                        splits_dir = processed_dir / "splits"
                        if splits_dir.exists():
                            splits = list(splits_dir.glob("*.txt"))
                            print(f"   üìÇ Splits disponibles: {len(splits)}")
                            for split_file in splits:
                                print(f"     üìä {split_file.name}")
                        
                        print("\nüí° Dataset listo para usar con modelo unificado")
                        
                    else:
                        print("‚ùå No se encontr√≥ dataset procesado")
                        print("üí° Ejecuta primero la opci√≥n 1 (Pipeline Completo)")
                else:
                    print("‚ùå Directorio data/processed/ no encontrado")
                    print("üí° Ejecuta primero la opci√≥n 1 (Pipeline Completo)")
                    
            elif choice == '4':
                return
            else:
                print("‚ùå Opci√≥n inv√°lida")
                
        except Exception as e:
            print(f"‚ùå Error en preprocessing: {e}")
        
        input("\nüìñ Presiona Enter para continuar...")


def main():
    """Main entry point for the Robo-Poet Academic Framework."""
    parser = argparse.ArgumentParser(
        description="üéì Robo-Poet Academic Neural Text Generation Framework",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python robo_poet.py                                                  # Interfaz acad√©mica interactiva
  python robo_poet.py --model mi_modelo --epochs 20                   # Entrenamiento multi-corpus (usa corpus/)
  python robo_poet.py --generate mi_modelo.keras                      # Generaci√≥n directa
  python robo_poet.py --generate mi_modelo.keras --seed "The power" --temp 0.8
  python robo_poet.py --surgery modelo.keras                          # Cirug√≠a de gates saturados
  python robo_poet.py --analyze modelo.keras --batches 30             # An√°lisis de gradientes
  python robo_poet.py --minima modelo.keras --config fast             # An√°lisis de paisaje de p√©rdida
  python robo_poet.py --ablation modelo.keras --experiments all       # Experimentos de ablaci√≥n
  python robo_poet.py --test quick                                    # Tests r√°pidos del M√≥dulo 2
  python robo_poet.py --test selective --test-selection training      # Tests espec√≠ficos

IMPORTANTE: El sistema ahora usa autom√°ticamente TODOS los archivos .txt en la carpeta 'corpus/'
            para entrenar modelos m√°s ricos y diversos. Simplemente pon tus textos en corpus/
        """
    )
    
    # Training arguments - now uses multi-corpus automatically
    parser.add_argument('--epochs', type=int, default=20, help='N√∫mero de √©pocas (default: 20)')
    parser.add_argument('--model', help='Nombre del modelo a entrenar (usa autom√°ticamente corpus/)')
    
    # Generation arguments
    parser.add_argument('--generate', help='Modelo para generaci√≥n de texto')
    parser.add_argument('--seed', default='The power of', help='Seed para generaci√≥n (default: "The power of")')
    parser.add_argument('--temp', '--temperature', type=float, default=0.8, 
                       help='Temperature para generaci√≥n (default: 0.8)')
    parser.add_argument('--length', type=int, default=200, help='Longitud de generaci√≥n (default: 200)')
    
    # Analysis and repair arguments (NEW)
    parser.add_argument('--surgery', help='Aplicar cirug√≠a de emergencia a modelo con gates saturados')
    parser.add_argument('--analyze', help='Analizar flujo de gradientes del modelo')
    parser.add_argument('--batches', type=int, default=30, help='Batches para an√°lisis (default: 30)')
    parser.add_argument('--minima', help='Analizar paisaje de p√©rdida (sharp vs flat minima)')
    parser.add_argument('--config', choices=['fast', 'standard', 'deep'], default='standard',
                       help='Configuraci√≥n de an√°lisis de minima: fast/standard/deep (default: standard)')
    parser.add_argument('--ablation', help='Ejecutar experimentos de ablaci√≥n sistem√°tica')
    parser.add_argument('--experiments', choices=['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim', 'all'], 
                       default='lstm_units', help='Tipo de experimentos de ablaci√≥n (default: lstm_units)')
    
    # Testing arguments (NEW)
    parser.add_argument('--test', choices=['quick', 'full', 'selective'], 
                       help='Ejecutar suite de tests del M√≥dulo 2')
    parser.add_argument('--test-selection', nargs='+',
                       choices=['training', 'gradient_analysis', 'minima_analysis', 
                               'ablation_experiments', 'emergency_surgery', 'report_generation'],
                       help='Tests espec√≠ficos para modo selective')
    
    args = parser.parse_args()
    
    # Initialize orchestrator
    orchestrator = RoboPoetOrchestrator()
    
    try:
        # Surgery mode (NEW)
        if args.surgery:
            from hospital.emergency_gate_surgery import quick_surgery
            print("üö® INICIANDO CIRUG√çA DE EMERGENCIA...")
            operated_model, report = quick_surgery(args.surgery)
            if operated_model:
                print("üéâ Cirug√≠a exitosa - modelo operado guardado")
                return 0
            else:
                print("‚ùå Cirug√≠a fall√≥")
                return 1
        
        # Gradient Analysis mode (NEW)
        elif args.analyze:
            from analysis.gradient_analyzer_lite import GradientAnalyzerLite
            print("üî¨ INICIANDO AN√ÅLISIS DE GRADIENTES...")
            analyzer = GradientAnalyzerLite(args.analyze)
            results = analyzer.run_complete_analysis(args.batches)
            if results:
                print("üéâ An√°lisis completo exitoso")
                return 0
            else:
                print("‚ùå An√°lisis fall√≥")
                return 1
        
        # Minima Analysis mode (NEW)
        elif args.minima:
            from analysis.minima_analyzer import analyze_model_sharpness
            print("üèîÔ∏è INICIANDO AN√ÅLISIS DE PAISAJE DE P√âRDIDA...")
            
            # Configure analysis based on --config argument
            if args.config == 'fast':
                config = {
                    'num_directions': 20,
                    'num_samples': 30,
                    'hessian_samples': 10,
                    'save_plots': True
                }
                print("‚ö° Configuraci√≥n r√°pida")
            elif args.config == 'deep':
                config = {
                    'num_directions': 100,
                    'num_samples': 200,
                    'hessian_samples': 50,
                    'save_plots': True
                }
                print("üî¨ Configuraci√≥n profunda")
            else:  # standard
                config = {
                    'num_directions': 50,
                    'num_samples': 100,
                    'hessian_samples': 20,
                    'save_plots': True
                }
                print("üìä Configuraci√≥n est√°ndar")
            
            try:
                results = analyze_model_sharpness(args.minima, config=config)
                if results:
                    classification = results.get('sharpness_classification', {})
                    print(f"\nüéâ AN√ÅLISIS COMPLETADO")
                    print(f"üè∑Ô∏è  Categor√≠a: {classification.get('category', 'N/A')}")
                    print(f"üìà Sharpness: {classification.get('overall_sharpness', 0):.4f}")
                    print(f"üí° {classification.get('interpretation', 'N/A')}")
                    return 0
                else:
                    print("‚ùå An√°lisis de minima fall√≥")
                    return 1
            except Exception as e:
                print(f"‚ùå Error en an√°lisis de minima: {e}")
                return 1
        
        # Ablation Study mode (NEW)
        elif args.ablation:
            from analysis.ablation_analyzer import run_quick_ablation_study
            print("üß™ INICIANDO EXPERIMENTOS DE ABLACI√ìN...")
            
            # Configure experiment types
            if args.experiments == 'all':
                experiment_types = ['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim']
                print("üîç Experimentos: Todos los componentes")
            else:
                experiment_types = [args.experiments]
                print(f"üìê Experimento: {args.experiments}")
            
            try:
                results = run_quick_ablation_study(
                    args.ablation, 
                    experiment_types=experiment_types
                )
                
                if results and not results.get('error'):
                    comparative = results.get('comparative_analysis', {})
                    best_overall = comparative.get('best_overall', {})
                    
                    if 'by_perplexity' in best_overall:
                        best = best_overall['by_perplexity']
                        print(f"\nüéâ EXPERIMENTOS COMPLETADOS")
                        print(f"üèÜ Mejor configuraci√≥n: {best['variant']}")
                        print(f"üìà Perplexity: {best['metrics']['perplexity']:.2f}")
                        print(f"üìä Visualizaci√≥n: {results.get('visualization_path', 'N/A')}")
                    return 0
                else:
                    error = results.get('error', 'Error desconocido')
                    print(f"‚ùå Experimentos fallaron: {error}")
                    return 1
                    
            except Exception as e:
                print(f"‚ùå Error en experimentos de ablaci√≥n: {e}")
                return 1
        
        # Testing mode (NEW)
        elif args.test:
            print("üß™ EJECUTANDO SUITE DE TESTS M√ìDULO 2...")
            
            if args.test == 'quick':
                from testing.module2_test_suite import run_quick_demo
                print("üöÄ Modo: Demo r√°pido")
                results = run_quick_demo()
                
            elif args.test == 'full':
                from testing.module2_test_suite import run_full_validation
                print("üî¨ Modo: Validaci√≥n completa")
                results = run_full_validation()
                
            elif args.test == 'selective':
                from testing.module2_test_suite import run_selected_tests
                test_selection = args.test_selection or ['training', 'gradient_analysis']
                print(f"üéØ Modo: Tests selectivos - {test_selection}")
                results = run_selected_tests(test_selection)
            
            if results and results.get('success'):
                stats = results.get('summary_statistics', {})
                print(f"\nüéâ TESTS COMPLETADOS EXITOSAMENTE")
                print(f"‚úÖ √âxito: {stats.get('successful_tests', 0)}/{stats.get('total_tests', 0)}")
                print(f"‚è±Ô∏è Tiempo: {stats.get('total_execution_time', 0):.2f}s")
                return 0
            else:
                print(f"\n‚ùå ALGUNOS TESTS FALLARON")
                return 1
        
        # Direct training mode - now uses multi-corpus automatically
        elif args.model:
            print(f"üöÄ ENTRENAMIENTO MULTI-CORPUS AUTOM√ÅTICO")
            print(f"   üìö Usando todos los textos de la carpeta 'corpus/'")
            print(f"   üéØ Modelo: {args.model}")
            print(f"   üìä √âpocas: {args.epochs}")
            return orchestrator.run_corpus_training(args.epochs, args.model)
        
        # Direct generation mode  
        elif args.generate:
            return orchestrator.run_direct_generation(args.generate, args.seed, args.temp, args.length)
        
        # Interactive mode (default)
        else:
            return orchestrator.run_interactive_mode()
    
    except KeyboardInterrupt:
        print("\nüéØ Proceso interrumpido por usuario")
        return 0
    except Exception as e:
        print(f"‚ùå Error cr√≠tico: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())