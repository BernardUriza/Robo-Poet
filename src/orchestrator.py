#!/usr/bin/env python3
"""
Robo-Poet Academic Framework Orchestrator

Main orchestrator for the modular academic text generation framework.
Coordinates all components and provides unified entry point.

Author: ML Academic Framework
Version: 2.1 - Modular Architecture
Hardware: Optimized for NVIDIA RTX 2000 Ada
Platform: WSL2 + Kali Linux + Windows 11
"""

import sys
import argparse
from pathlib import Path
from typing import Optional, Dict, List

# Conditional numpy import for testing
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("âš ï¸ Numpy no disponible - algunas funcionalidades limitadas")

# Import core modules safely
import os
import json

# Configure environment for potential GPU use
conda_prefix = os.getenv('CONDA_PREFIX', '/usr/local')
if conda_prefix != '/usr/local':
    os.environ['CUDA_HOME'] = conda_prefix
    os.environ['LD_LIBRARY_PATH'] = f'{conda_prefix}/lib:{conda_prefix}/lib64:{os.environ.get("LD_LIBRARY_PATH", "")}'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    # PyTorch environment optimizations

# Configure PyTorch environment
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'

# Import with fallbacks
gpu_available = False
torch_module = None

# Try to import PyTorch
try:
    import torch
    torch_module = torch
    gpu_available = torch.cuda.is_available()
    if gpu_available:
        print(f"ğŸ”¥ PyTorch GPU available: {torch.cuda.get_device_name(0)}")
except ImportError:
    print("âš ï¸ PyTorch no disponible - modo CPU solamente")

try:
    from core.unified_config import get_config
except ImportError:
    # Fallback to basic config
    def get_config():
        from types import SimpleNamespace
        return SimpleNamespace(
            gpu=SimpleNamespace(mixed_precision=True, memory_growth=True),
            model=SimpleNamespace(batch_size=32, epochs=10),
            system=SimpleNamespace(debug=True)
        )

# GPU detection with PyTorch
try:
    if torch_module and torch_module.cuda.is_available():
        gpu_available = True
        print(f"ğŸ¯ PyTorch GPU funcionando correctamente: {torch_module.cuda.get_device_name(0)}")
    else:
        gpu_available = False
        if torch_module:
            print("âš ï¸ PyTorch disponible pero GPU no detectada")
        else:
            print("âš ï¸ PyTorch no disponible")
except Exception as e:
    print(f"âš ï¸ GPU no disponible, continuando sin GPU: {e}")
    gpu_available = False

# Import framework components with fallbacks
try:
    from interface.menu_system import AcademicMenuSystem
except ImportError as e:
    print(f"âš ï¸ Menu system not available: {e}")
    AcademicMenuSystem = None

try:
    from interface.phase1_training import Phase1TrainingInterface
except ImportError as e:
    print(f"âš ï¸ Phase1 interface not available: {e}")
    Phase1TrainingInterface = None

try:
    from interface.phase2_generation import Phase2GenerationInterface
except ImportError as e:
    print(f"âš ï¸ Phase2 interface not available: {e}")
    Phase2GenerationInterface = None

try:
    from utils.file_manager import FileManager
except ImportError as e:
    print(f"âš ï¸ File manager not available: {e}")
    FileManager = None

try:
    from utils.display_utils import DisplayUtils
except ImportError as e:
    print(f"âš ï¸ Display utils not available: {e}")
    DisplayUtils = None

try:
    from utils.input_validator import InputValidator
except ImportError as e:
    print(f"âš ï¸ Input validator not available: {e}")
    InputValidator = None

# Import PyTorch model components
try:
    from model_pytorch import create_model, RoboPoetModel
    MODEL_TYPE = "PyTorch GPT"
    print("ğŸš€ Using PyTorch GPT model (modern transformer architecture)")
except ImportError as e:
    print(f"âŒ PyTorch model not available: {e}")
    print("   Please ensure PyTorch is installed and robo-poet-pytorch directory exists")
    create_model = None
    RoboPoetModel = None
    MODEL_TYPE = "PyTorch GPT (Not Available)"


class RoboPoetOrchestrator:
    """Main orchestrator for the Robo-Poet Academic Framework."""
    
    def __init__(self):
        """Initialize orchestrator with all components."""
        self.config = get_config()
        
        # Show current model type
        print(f"ğŸ¤– Model System: {MODEL_TYPE}")
        
        # Academic Performance GPU Requirement
        if torch_module and not torch_module.cuda.is_available():
            print("ğŸ“ ACADEMIC PERFORMANCE WARNING:")
            print("   ğŸ“š GPU/CUDA not available - academic benchmarks require GPU")
            print("   ğŸ”§ Install CUDA-enabled PyTorch for optimal performance")
        elif torch_module and torch_module.cuda.is_available():
            print(f"ğŸ”¥ Academic Performance Mode: GPU Available")
            print(f"   ğŸ® GPU: {torch_module.cuda.get_device_name(0)}")
        
        # Initialize components with fallbacks
        self.menu_system = AcademicMenuSystem() if AcademicMenuSystem else None
        self.phase1_interface = Phase1TrainingInterface(self.config) if Phase1TrainingInterface else None
        self.phase2_interface = Phase2GenerationInterface(self.config) if Phase2GenerationInterface else None
        self.file_manager = FileManager() if FileManager else None
        self.display = DisplayUtils() if DisplayUtils else None
        
        # GPU availability
        self.gpu_available = gpu_available
        self.torch_module = torch_module
    
    def _safe_display(self, method_name, *args, **kwargs):
        """Safely call display methods with fallback."""
        if self.display and hasattr(self.display, method_name):
            return getattr(self.display, method_name)(*args, **kwargs)
        else:
            # Fallback to simple print
            if method_name == 'show_error':
                print(f"âŒ {args[0] if args else 'Error'}")
            elif method_name == 'show_warning':
                print(f"âš ï¸ {args[0] if args else 'Warning'}")
            elif method_name == 'pause_for_user':
                input("Presiona Enter para continuar...")
            else:
                print(f"â„¹ï¸ {args[0] if args else 'Info'}")
    
    def _safe_file_manager(self, method_name, *args, **kwargs):
        """Safely call file manager methods with fallback."""
        if self.file_manager and hasattr(self.file_manager, method_name):
            return getattr(self.file_manager, method_name)(*args, **kwargs)
        else:
            print(f"âŒ File manager no disponible para {method_name}")
            return None
    
    def run_interactive_mode(self) -> int:
        """Run the main interactive academic interface."""
        if not self.menu_system:
            print("âŒ Sistema de menÃºs no disponible. Por favor instala las dependencias faltantes.")
            return 1
            
        try:
            while True:
                self.menu_system.show_header()
                choice = self.menu_system.show_main_menu()
                
                if choice == '1':
                    # Phase 1: Intensive Training
                    if not self.phase1_interface:
                        print("âŒ Interfaz de entrenamiento no disponible.")
                        continue
                        
                    if not self.gpu_available:
                        self._safe_display('show_warning',
                            "GPU no disponible. Se recomienda GPU para entrenamiento eficiente."
                        )
                        
                        # Simple confirmation without InputValidator if not available
                        response = input("Â¿Continuar de todas formas? (y/N): ").lower().strip()
                        if response not in ('y', 'yes', 's', 'si'):
                            continue
                    
                    self.phase1_interface.run_intensive_training()
                
                elif choice == '2':
                    # Phase 2: Text Generation
                    if not self.phase2_interface:
                        print("âŒ Interfaz de generaciÃ³n no disponible.")
                        continue
                    self.phase2_interface.run_generation_studio()
                
                elif choice == '3':
                    # View Available Models
                    self._show_available_models()
                
                elif choice == '4':
                    # HOSPITAL - CirugÃ­a de Gates (NEW)
                    self._run_gate_surgery()
                
                elif choice == '5':
                    # ANÃLISIS - Gradient Flow Analysis (NEW)
                    self._run_gradient_analysis()
                
                elif choice == '6':
                    # Monitor Training Progress
                    self._monitor_training_progress()
                
                elif choice == '7':
                    # Clean All Models
                    self._clean_all_models()
                
                elif choice == '8':
                    # Test Suite MÃ³dulo 2
                    self._run_test_suite()
                
                elif choice == 'A':
                    # Ver Logs y Archivos Generados
                    self._view_logs_and_files()
                
                elif choice == 'B':
                    # Explorar Visualizaciones y GrÃ¡ficos
                    self._explore_visualizations()
                
                elif choice == 'C':
                    # Attention Mechanism Demo & Validation
                    self._run_attention_demos()
                
                elif choice == 'D':
                    # Dataset Preprocessing Pipeline
                    self._run_dataset_preprocessing()
                
                elif choice == '9':
                    # System Configuration and Status
                    self.menu_system.show_system_status()
                
                elif choice == '0':
                    # Exit
                    self.menu_system.show_exit_message()
                    return 0
                
                else:
                    print("âŒ OpciÃ³n invÃ¡lida. Por favor selecciona 0-9, A-B.")
                    self.display.pause_for_user()
        
        except KeyboardInterrupt:
            print("\n\nğŸ¯ Sistema interrumpido por usuario")
            self.menu_system.show_exit_message()
            return 0
        except Exception as e:
            self.display.show_error(f"Error crÃ­tico en orchestrator: {e}")
            return 1
    
    def run_direct_training(self, text_file: str, epochs: int, model_name: str) -> int:
        """Run direct training mode (CLI) with mandatory model name."""
        try:
            if not self.gpu_available:
                print("âš ï¸ GPU no disponible - entrenamiento serÃ¡ lento en CPU")
            
            print(f"ğŸš€ Modo directo: Entrenando modelo '{model_name}' con {text_file} por {epochs} Ã©pocas")
            
            # Validate parameters
            if not Path(text_file).exists():
                self.display.show_error(f"Archivo no encontrado: {text_file}")
                return 1
            
            valid, message = self.file_manager.validate_text_file(text_file)
            if not valid:
                self.display.show_error(message)
                return 1
            
            # Import training modules
            from data_processor import TextProcessor
            from model import LSTMTextGenerator, ModelTrainer, ModelManager
            import json
            from datetime import datetime
            
            print("âœ… Archivo vÃ¡lido, iniciando entrenamiento...")
            
            # Prepare data
            processor = TextProcessor(
                sequence_length=self.config.model.sequence_length,
                step_size=3  # Fixed step size for sliding window
            )
            
            # Load and prepare multi-corpus text
            X_onehot, y_onehot = processor.prepare_data("corpus", max_length=500_000)
            
            # Convert one-hot to integer encoding for embedding layer
            X = np.argmax(X_onehot, axis=-1)  # Shape: (samples, sequence_length)
            y = np.argmax(y_onehot, axis=-1)  # Shape: (samples,)
            
            # Build model
            model_builder = LSTMTextGenerator(
                vocab_size=processor.vocab_size,
                sequence_length=self.config.model.sequence_length,
                lstm_units=self.config.model.lstm_units[0] if isinstance(self.config.model.lstm_units, list) else self.config.model.lstm_units,
                variational_dropout_rate=self.config.model.dropout_rate
            )
            model = model_builder.build_model()
            
            # Train model - GPU MANDATORY, no CPU fallback
            if not self.gpu_available:
                print("\nğŸ”´ SISTEMA TERMINADO: GPU es obligatoria para este proyecto acadÃ©mico")
                import sys
                sys.exit(1)
            
            device = '/GPU:0'  # FIXED: Always GPU, no fallback
            trainer = ModelTrainer(model, device)
            
            history = trainer.train(
                X, y,
                batch_size=self.config.model.batch_size,
                epochs=epochs,
                validation_split=self.config.data.validation_split
            )
            
            # Save model and metadata with user-provided name
            model_filename = f"{model_name}.keras"
            model_path = self.file_manager.models_dir / model_filename
            
            ModelManager.save_model(model, str(model_path))
            
            # Save metadata
            metadata = {
                'model_name': model_name,
                'model_file': model_filename,
                'training_file': text_file,
                'epochs': epochs,
                'final_epoch': len(history.history['loss']),
                'final_loss': float(history.history['loss'][-1]),
                'final_accuracy': float(history.history['accuracy'][-1]),
                'vocab_size': processor.vocab_size,
                'sequence_length': self.config.model.sequence_length,
                'lstm_units': self.config.model.lstm_units,
                'dropout_rate': self.config.model.dropout_rate,
                'batch_size': self.config.model.batch_size,
                'char_to_idx': processor.token_to_idx,  # Legacy name kept for compatibility
                'idx_to_char': processor.idx_to_token,  # Legacy name kept for compatibility
                'token_to_idx': processor.token_to_idx,
                'idx_to_token': processor.idx_to_token,
                'training_start_time': datetime.now().isoformat(),
                'training_end_time': datetime.now().isoformat(),
                'gpu_used': self.gpu_available
            }
            
            metadata_path = self.file_manager.models_dir / f"{model_name}_metadata.json"
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            print(f"âœ… Entrenamiento completado exitosamente")
            print(f"ğŸ·ï¸  Modelo '{model_name}' guardado")
            print(f"ğŸ’¾ Archivo: {model_path}")
            print(f"ğŸ“‹ Metadata: {metadata_path}")
            print(f"ğŸ¨ Ahora puedes usar: python robo_poet.py --generate {model_filename}")
            
            return 0
            
        except Exception as e:
            self.display.show_error(f"Error en entrenamiento directo: {e}")
            return 1
    
    def run_corpus_training(self, epochs: int, model_name: str) -> int:
        """
        Run multi-corpus training mode - automatically uses all texts in corpus/.
        This is the new preferred method that replaces single-file training.
        """
        return self.run_direct_training("corpus", epochs, model_name)
    
    def run_direct_generation(self, model_path: str, seed: str = "The power of", 
                             temperature: float = 0.8, length: int = 200) -> int:
        """Run direct generation mode (CLI)."""
        try:
            if not Path(model_path).exists():
                self.display.show_error(f"Modelo no encontrado: {model_path}")
                return 1
            
            print(f"ğŸ¨ Generando texto con modelo: {Path(model_path).name}")
            
            # Import generation modules
            from model import ModelManager
            from data_processor import TextGenerator
            import json
            
            # Load model
            model_manager = ModelManager()
            model = model_manager.load_model(model_path)
            
            if not model:
                self.display.show_error("No se pudo cargar el modelo")
                return 1
            
            # Load metadata
            metadata_path = Path(model_path).parent / (Path(model_path).stem + '_metadata.json')
            if metadata_path.exists():
                with open(metadata_path) as f:
                    metadata = json.load(f)
                # Support both old and new naming conventions
                char_to_idx = metadata.get('token_to_idx', metadata.get('char_to_idx', {}))
                raw_idx_to_char = metadata.get('idx_to_token', metadata.get('idx_to_char', {}))
                idx_to_char = {int(k): v for k, v in raw_idx_to_char.items()}
            else:
                self.display.show_error("Metadata no encontrada - no se puede generar texto")
                return 1
            
            # Generate text
            generator = TextGenerator(model, char_to_idx, idx_to_char, tokenization='word')
            result = generator.generate(seed, length, temperature)
            
            # Display result
            self.display.format_generation_result(
                result, seed, temperature, length, 0, Path(model_path).name
            )
            
            return 0
            
        except Exception as e:
            self.display.show_error(f"Error en generaciÃ³n directa: {e}")
            return 1
    
    def _show_available_models(self) -> None:
        """Show available models with enhanced information."""
        print("\nğŸ“Š MODELOS DISPONIBLES")
        print("=" * 60)
        
        models = self.file_manager.list_available_models_enhanced()
        
        if not models:
            print("ğŸ“­ No hay modelos entrenados disponibles")
            print("ğŸ’¡ Ejecuta FASE 1: Entrenamiento Intensivo para crear modelos")
        else:
            print(f"ğŸ“ˆ Total de modelos: {len(models)}")
            print()
            
            for i, model_info in enumerate(models, 1):
                print(f"{i}. ", end="")
                self.display.format_model_info(model_info)
        
        self.display.pause_for_user()
    
    def _monitor_training_progress(self) -> None:
        """Monitor training progress (placeholder for advanced monitoring)."""
        print("\nğŸ“ˆ MONITOREO DE PROGRESO DE ENTRENAMIENTO")
        print("=" * 60)
        print("ğŸ” Buscando entrenamientos activos...")
        
        # Check for active TensorBoard logs
        if self.file_manager.logs_dir.exists():
            log_files = list(self.file_manager.logs_dir.glob("*"))
            if log_files:
                print(f"ğŸ“Š Encontrados {len(log_files)} logs de entrenamiento")
                print("ğŸ’¡ Para monitoreo en tiempo real:")
                print("   tensorboard --logdir logs --port 6006")
                print("   Luego abre: http://localhost:6006")
            else:
                print("ğŸ“­ No hay logs de entrenamiento disponibles")
        else:
            print("ğŸ“­ Directorio de logs no encontrado")
        
        print("\nğŸ’¡ HERRAMIENTAS DE MONITOREO:")
        print("   ğŸ–¥ï¸ GPU: nvidia-smi")
        print("   ğŸ“Š TensorBoard: tensorboard --logdir logs")
        print("   ğŸ”„ Tiempo real: watch nvidia-smi")
        
        self.display.pause_for_user()
    
    def _run_gate_surgery(self) -> None:
        """
        ğŸ¥ HOSPITAL - Ejecutar cirugÃ­a de emergencia en modelo con gates saturados
        """
        print("\nğŸ¥ HOSPITAL - CIRUGÃA DE GATES LSTM")
        print("=" * 50)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("ğŸ“­ No hay modelos disponibles para cirugÃ­a")
            self.display.pause_for_user()
            return
        
        print("ğŸ“Š Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            print(f"   {i}. {model_name}")
        
        print("\nğŸ” Selecciona el modelo a diagnosticar:")
        try:
            choice = input("   NÃºmero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("âŒ CirugÃ­a cancelada")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nğŸ”¬ Modelo seleccionado: {Path(selected_model).name}")
                print("âš ï¸  La cirugÃ­a modificarÃ¡ permanentemente los gates del modelo")
                
                confirm = input("\nÂ¿Proceder con la cirugÃ­a? (s/N): ").lower().strip()
                
                if confirm in ('s', 'si', 'y', 'yes'):
                    # Ejecutar cirugÃ­a
                    from hospital.emergency_gate_surgery import quick_surgery
                    
                    print("\nğŸš¨ INICIANDO CIRUGÃA DE EMERGENCIA...")
                    operated_model, report = quick_surgery(selected_model)
                    
                    if operated_model and report:
                        print("\nğŸ‰ CIRUGÃA EXITOSA")
                        print("ğŸ“Š El modelo fue operado y guardado con prefijo 'operated_'")
                        print("ğŸ“‹ Reporte de cirugÃ­a guardado en src/hospital/")
                    else:
                        print("\nâŒ La cirugÃ­a fallÃ³")
                else:
                    print("âŒ CirugÃ­a cancelada")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
        except Exception as e:
            self.display.show_error(f"Error en cirugÃ­a: {e}")
        
        self.display.pause_for_user()
    
    def _run_gradient_analysis(self) -> None:
        """
        ğŸ”¬ ANÃLISIS - Ejecutar anÃ¡lisis profundo de gradient flow
        """
        print("\nğŸ”¬ ANÃLISIS PROFUNDO DE MODELOS LSTM")
        print("=" * 60)
        print("ğŸ“‹ MENÃš DE ANÃLISIS DISPONIBLES:")
        print()
        print("ğŸ”¬ DIAGNÃ“STICOS DE GRADIENTES:")
        print("1. ğŸ“ˆ Gradient Flow Analysis")
        print("   â€¢ DetecciÃ³n de vanishing/exploding gradients") 
        print("   â€¢ AnÃ¡lisis de propagaciÃ³n por capas")
        print("   â€¢ MÃ©tricas de Pascanu et al. 2013")
        print()
        print("ğŸ”ï¸  ANÃLISIS DE PAISAJE DE PÃ‰RDIDA:")
        print("2. ğŸ¯ Sharp vs Flat Minima Detection")
        print("   â€¢ AnÃ¡lisis de sharpness del mÃ­nimo actual")
        print("   â€¢ PredicciÃ³n de capacidad de generalizaciÃ³n")
        print("   â€¢ VisualizaciÃ³n de curvatura Hessiana")
        print()
        print("ğŸš€ ANÃLISIS INTEGRAL:")
        print("3. ğŸ” Suite Completa de AnÃ¡lisis")
        print("   â€¢ Combina ambos anÃ¡lisis anteriores")
        print("   â€¢ Reporte consolidado de diagnÃ³stico")
        print("   â€¢ Recomendaciones integradas")
        print()
        print("ğŸ§ª EXPERIMENTOS DE ABLACIÃ“N:")
        print("4. âš—ï¸ Ablation Study (Componente Impact)")
        print("   â€¢ Identifica componentes crÃ­ticos del modelo")
        print("   â€¢ Compara variantes arquitectÃ³nicas")
        print("   â€¢ OptimizaciÃ³n sistemÃ¡tica de hiperparÃ¡metros")
        print()
        print("=" * 60)
        
        choice = input("ğŸ¯ Selecciona anÃ¡lisis (1-4): ").strip()
        
        if choice == "1":
            self._run_gradient_flow_analysis()
        elif choice == "2":
            self._run_minima_analysis()
        elif choice == "3":
            self._run_gradient_flow_analysis()
            print("\n" + "="*50)
            self._run_minima_analysis()
        elif choice == "4":
            self._run_ablation_study()
        else:
            print("âŒ OpciÃ³n invÃ¡lida")
            self.display.pause_for_user()
    
    def _run_gradient_flow_analysis(self) -> None:
        """Ejecutar anÃ¡lisis de gradient flow especÃ­ficamente."""
        print("\nğŸ“ˆ ANÃLISIS DE GRADIENT FLOW")
        print("=" * 50)
        print("ğŸ”¬ ENTRADA: Modelo LSTM entrenado")
        print("ğŸ“Š SALIDA: MÃ©tricas de gradientes, grÃ¡ficos y reporte JSON")
        print("â±ï¸  TIEMPO: ~2-5 minutos segÃºn nÃºmero de batches")
        print("=" * 50)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("ğŸ“­ No hay modelos disponibles para anÃ¡lisis")
            self.display.pause_for_user()
            return
        
        print("ğŸ“Š Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            # Marcar modelos operados
            if 'operated' in model_name:
                print(f"   {i}. {model_name} ğŸ¥ (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nğŸ” Selecciona el modelo a analizar:")
        try:
            choice = input("   NÃºmero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("âŒ AnÃ¡lisis cancelado")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nğŸ“Š Modelo seleccionado: {Path(selected_model).name}")
                
                # Solicitar nÃºmero de batches
                batches_input = input("ğŸ“ˆ NÃºmero de batches a analizar (default: 30): ").strip()
                num_batches = int(batches_input) if batches_input else 30
                
                # Ejecutar anÃ¡lisis
                from analysis.gradient_analyzer_lite import GradientAnalyzerLite
                
                print(f"\nğŸ”¬ INICIANDO ANÃLISIS ({num_batches} batches)...")
                analyzer = GradientAnalyzerLite(selected_model)
                results = analyzer.run_complete_analysis(num_batches)
                
                if results:
                    print("\nğŸ‰ ANÃLISIS DE GRADIENTES COMPLETADO")
                    print("=" * 55)
                    
                    # Mostrar resumen de resultados
                    collapse_info = results.get('collapse_analysis', {})
                    pascanu_info = results.get('pascanu_analysis', {})
                    
                    print("ğŸ“Š DIAGNÃ“STICO DE GRADIENTES:")
                    print(f"â”Œ{'â”€' * 53}â”")
                    
                    if collapse_info.get('earliest_collapse', -1) >= 0:
                        print(f"â”‚ ğŸ”´ Colapso en batch: {collapse_info['earliest_collapse']:<32} â”‚")
                    else:
                        print(f"â”‚ âœ… Sin colapso detectado{' ' * 32} â”‚")
                    
                    vanishing_status = "âš ï¸  SÃ" if pascanu_info.get('has_vanishing') else "âœ… NO"
                    exploding_status = "âš ï¸  SÃ" if pascanu_info.get('has_exploding') else "âœ… NO"
                    
                    print(f"â”‚ ğŸ“‰ Vanishing gradients: {vanishing_status:<28} â”‚")
                    print(f"â”‚ ğŸ“ˆ Exploding gradients: {exploding_status:<28} â”‚")
                    print(f"â””{'â”€' * 53}â”˜")
                    
                    # Status general
                    if not pascanu_info.get('has_vanishing') and not pascanu_info.get('has_exploding'):
                        print("\nğŸ¯ ESTADO: Flujo de gradientes ESTABLE - Modelo saludable")
                    else:
                        print("\nâš ï¸  ESTADO: Problemas detectados - Considerar ajustes")
                    
                    print(f"\nğŸ“ ARCHIVOS GENERADOS:")
                    print(f"   ğŸ“Š CSV: gradient_tracking_*.csv")
                    print(f"   ğŸ“ˆ VisualizaciÃ³n: gradient_analysis_*.png")
                    print(f"   ğŸ“‹ Reporte JSON: gradient_analysis_lite_*.json")
                else:
                    print("\nâŒ El anÃ¡lisis fallÃ³")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
        except Exception as e:
            self.display.show_error(f"Error en anÃ¡lisis: {e}")
        
        self.display.pause_for_user()
    
    def _run_minima_analysis(self) -> None:
        """Ejecutar anÃ¡lisis de Sharp vs Flat Minima."""
        print("\nğŸ”ï¸ ANÃLISIS DE PAISAJE DE PÃ‰RDIDA (SHARP VS FLAT MINIMA)")
        print("=" * 70)
        print("ğŸ”¬ ENTRADA: Modelo LSTM entrenado")
        print("ğŸ“Š SALIDA: ClasificaciÃ³n de sharpness, visualizaciÃ³n del paisaje")
        print("â±ï¸  TIEMPO: ~5-15 minutos segÃºn configuraciÃ³n")
        print("ğŸ¯ PROPÃ“SITO: Predecir capacidad de generalizaciÃ³n del modelo")
        print("=" * 70)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("ğŸ“­ No hay modelos disponibles para anÃ¡lisis")
            self.display.pause_for_user()
            return
        
        print("ğŸ“Š Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            if 'operated' in model_name:
                print(f"   {i}. {model_name} ğŸ¥ (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nğŸ” Selecciona el modelo a analizar:")
        try:
            choice = input("   NÃºmero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("âŒ AnÃ¡lisis cancelado")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nğŸ“Š Modelo seleccionado: {Path(selected_model).name}")
                print("ğŸ”¬ Configurando anÃ¡lisis de paisaje de pÃ©rdida...")
                
                # ConfiguraciÃ³n de anÃ¡lisis
                print("\nâš™ï¸ CONFIGURACIÃ“N DEL ANÃLISIS:")
                print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                print("â”‚ 1. ğŸš€ RÃPIDO    â”‚ 20 direcciones â”‚ 30 muestras  â”‚ ~2-3 min â”‚")
                print("â”‚ 2. ğŸ“Š ESTÃNDAR  â”‚ 50 direcciones â”‚ 100 muestras â”‚ ~5-8 min â”‚") 
                print("â”‚ 3. ğŸ”¬ PROFUNDO  â”‚ 100 direccionesâ”‚ 200 muestras â”‚ ~10-15minâ”‚")
                print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
                print("ğŸ’¡ MÃ¡s direcciones = mayor precisiÃ³n en detecciÃ³n de sharpness")
                
                config_choice = input("Selecciona configuraciÃ³n (1-3, default: 2): ").strip()
                
                # Configurar parÃ¡metros segÃºn elecciÃ³n
                if config_choice == "1":
                    config = {
                        'num_directions': 20,
                        'num_samples': 30,
                        'hessian_samples': 10,
                        'save_plots': True
                    }
                    print("âš¡ ConfiguraciÃ³n rÃ¡pida seleccionada")
                elif config_choice == "3":
                    config = {
                        'num_directions': 100,
                        'num_samples': 200,
                        'hessian_samples': 50,
                        'save_plots': True
                    }
                    print("ğŸ”¬ ConfiguraciÃ³n profunda seleccionada")
                else:
                    config = {
                        'num_directions': 50,
                        'num_samples': 100,
                        'hessian_samples': 20,
                        'save_plots': True
                    }
                    print("ğŸ“Š ConfiguraciÃ³n estÃ¡ndar seleccionada")
                
                # Ejecutar anÃ¡lisis
                from analysis.minima_analyzer import analyze_model_sharpness
                
                print(f"\nğŸ”¬ INICIANDO ANÃLISIS DE SHARPNESS...")
                print("â³ Este proceso puede tomar varios minutos...")
                
                try:
                    results = analyze_model_sharpness(selected_model, config=config)
                    
                    if results:
                        print("\nğŸ‰ ANÃLISIS DE SHARPNESS COMPLETADO")
                        print("=" * 60)
                        
                        # Mostrar resumen de resultados
                        classification = results.get('sharpness_classification', {})
                        
                        print("ğŸ“Š RESULTADO DEL ANÃLISIS:")
                        print(f"â”Œ{'â”€' * 58}â”")
                        print(f"â”‚ ğŸ·ï¸  CategorÃ­a: {classification.get('category', 'N/A'):<44} â”‚")
                        print(f"â”‚ ğŸ“ˆ Sharpness: {classification.get('overall_sharpness', 0):<45.4f} â”‚")
                        print(f"â””{'â”€' * 58}â”˜")
                        print()
                        print(f"ğŸ’¡ INTERPRETACIÃ“N:")
                        print(f"   {classification.get('interpretation', 'N/A')}")
                        
                        # Mostrar recomendaciones
                        recommendations = results.get('recommendations', [])
                        if recommendations:
                            print("\nğŸ’¡ RECOMENDACIONES:")
                            for rec in recommendations:
                                print(f"   â€¢ {rec}")
                        
                        # InformaciÃ³n de archivos generados
                        viz_path = results.get('visualization_path')
                        if viz_path:
                            print(f"\nğŸ“ Archivos generados:")
                            print(f"   ğŸ“ˆ VisualizaciÃ³n: {viz_path}")
                            print(f"   ğŸ“‹ Reporte JSON: minima_analysis_*.json")
                        
                        # Mostrar mÃ©tricas tÃ©cnicas adicionales
                        perturbation = results.get('perturbation_analysis', {})
                        curvature = results.get('curvature_analysis', {})
                        
                        if perturbation:
                            print(f"\nğŸ“Š MÃ‰TRICAS TÃ‰CNICAS:")
                            print(f"   ğŸ“ Loss baseline: {perturbation.get('baseline_loss', 0):.4f}")
                        
                        if curvature:
                            print(f"   ğŸ”¢ Max eigenvalue: {curvature.get('max_eigenvalue', 0):.4f}")
                            print(f"   ğŸ“ Condition number: {curvature.get('condition_number', 0):.2f}")
                    else:
                        print("\nâŒ El anÃ¡lisis de sharpness fallÃ³")
                        
                except Exception as e:
                    print(f"\nâŒ Error durante anÃ¡lisis: {e}")
                    print("ğŸ’¡ Tip: AsegÃºrate de que el modelo sea compatible")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
        except Exception as e:
            self.display.show_error(f"Error en anÃ¡lisis de minima: {e}")
        
        self.display.pause_for_user()
    
    def _run_ablation_study(self) -> None:
        """Ejecutar experimentos de ablaciÃ³n sistemÃ¡tica."""
        print("\nğŸ§ª EXPERIMENTOS DE ABLACIÃ“N SISTEMÃTICA")
        print("=" * 60)
        print("ğŸ”¬ ENTRADA: Modelo LSTM entrenado")
        print("ğŸ“Š SALIDA: AnÃ¡lisis comparativo de componentes")
        print("â±ï¸  TIEMPO: ~15-30 minutos segÃºn configuraciÃ³n")
        print("ğŸ¯ PROPÃ“SITO: Identificar componentes crÃ­ticos del modelo")
        print("=" * 60)
        
        # Listar modelos disponibles
        models = self.file_manager.list_available_models()
        
        if not models:
            print("ğŸ“­ No hay modelos disponibles para anÃ¡lisis")
            self.display.pause_for_user()
            return
        
        print("ğŸ“Š Modelos disponibles:")
        for i, model_path in enumerate(models, 1):
            model_name = Path(model_path).name
            if 'operated' in model_name:
                print(f"   {i}. {model_name} ğŸ¥ (operado)")
            else:
                print(f"   {i}. {model_name}")
        
        print("\nğŸ” Selecciona el modelo para ablaciÃ³n:")
        try:
            choice = input("   NÃºmero (o 'c' para cancelar): ").strip()
            
            if choice.lower() == 'c':
                print("âŒ Experimentos cancelados")
                self.display.pause_for_user()
                return
            
            model_idx = int(choice) - 1
            if 0 <= model_idx < len(models):
                selected_model = models[model_idx]
                
                print(f"\nğŸ“Š Modelo seleccionado: {Path(selected_model).name}")
                print("ğŸ”¬ Configurando experimentos de ablaciÃ³n...")
                
                # SelecciÃ³n de tipos de experimento
                print("\nâš™ï¸ TIPOS DE EXPERIMENTO DISPONIBLES:")
                print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                print("â”‚ 1. ğŸ“ LSTM Units    â”‚ Impacto del tamaÃ±o de capas   â”‚")
                print("â”‚ 2. ğŸ—ï¸  LSTM Layers   â”‚ Efecto del nÃºmero de capas    â”‚") 
                print("â”‚ 3. ğŸ’§ Dropout Rate  â”‚ Influencia de regularizaciÃ³n  â”‚")
                print("â”‚ 4. ğŸ“š Embeddings    â”‚ Dimensiones de representaciÃ³n â”‚")
                print("â”‚ 5. ğŸ” Completo      â”‚ Todos los experimentos        â”‚")
                print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
                
                exp_choice = input("Selecciona tipo de experimento (1-5, default: 1): ").strip()
                
                # Configurar experimentos segÃºn elecciÃ³n
                if exp_choice == "2":
                    experiment_types = ['lstm_layers']
                    print("ğŸ—ï¸ Experimento: NÃºmero de capas LSTM")
                elif exp_choice == "3":
                    experiment_types = ['dropout_rate']
                    print("ğŸ’§ Experimento: Dropout rate")
                elif exp_choice == "4":
                    experiment_types = ['embedding_dim']
                    print("ğŸ“š Experimento: Dimensiones de embedding")
                elif exp_choice == "5":
                    experiment_types = ['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim']
                    print("ğŸ” Experimento completo: Todos los componentes")
                else:  # Default: lstm_units
                    experiment_types = ['lstm_units']
                    print("ğŸ“ Experimento: TamaÃ±o de unidades LSTM")
                
                # Configurar velocidad del experimento
                print("\nâš¡ CONFIGURACIÃ“N DE VELOCIDAD:")
                print("1. ğŸš€ RÃ¡pido (3 Ã©pocas, datos sintÃ©ticos) - ~5 min")
                print("2. ğŸ“Š EstÃ¡ndar (5 Ã©pocas, datos sintÃ©ticos) - ~15 min")
                print("3. ğŸ”¬ Completo (10 Ã©pocas, datos reales si disponible) - ~30+ min")
                
                speed_choice = input("Selecciona velocidad (1-3, default: 1): ").strip()
                
                if speed_choice == "2":
                    epochs = 5
                    quick_mode = True
                    print("ğŸ“Š ConfiguraciÃ³n estÃ¡ndar seleccionada")
                elif speed_choice == "3":
                    epochs = 10
                    quick_mode = False
                    print("ğŸ”¬ ConfiguraciÃ³n completa seleccionada")
                else:
                    epochs = 3
                    quick_mode = True
                    print("ğŸš€ ConfiguraciÃ³n rÃ¡pida seleccionada")
                
                # Ejecutar experimentos
                from analysis.ablation_analyzer import AblationExperimentRunner
                
                print(f"\nğŸ§ª INICIANDO EXPERIMENTOS DE ABLACIÃ“N...")
                print("â³ Este proceso puede tomar tiempo...")
                print("ğŸ“Š Se entrenarÃ¡n mÃºltiples variantes del modelo...")
                
                try:
                    runner = AblationExperimentRunner(selected_model)
                    results = runner.run_ablation_study(
                        experiment_types=experiment_types,
                        epochs=epochs,
                        quick_mode=quick_mode
                    )
                    
                    if results and not results.get('error'):
                        print("\nğŸ‰ EXPERIMENTOS DE ABLACIÃ“N COMPLETADOS")
                        print("=" * 50)
                        
                        # Mostrar resultados principales
                        comparative = results.get('comparative_analysis', {})
                        best_overall = comparative.get('best_overall', {})
                        
                        if 'by_perplexity' in best_overall:
                            best = best_overall['by_perplexity']
                            print("ğŸ† MEJOR CONFIGURACIÃ“N ENCONTRADA:")
                            print(f"â”Œ{'â”€' * 48}â”")
                            print(f"â”‚ Experimento: {best['experiment']:<32} â”‚")
                            print(f"â”‚ Variante: {best['variant']:<35} â”‚")
                            print(f"â”‚ Perplexity: {best['metrics']['perplexity']:<31.2f} â”‚")
                            print(f"â”‚ ParÃ¡metros: {best['metrics']['total_params']:<29,} â”‚")
                            print(f"â””{'â”€' * 48}â”˜")
                        
                        # Mostrar insights de ablaciÃ³n
                        insights = comparative.get('ablation_insights', {})
                        if insights:
                            print("\nğŸ’¡ INSIGHTS DE COMPONENTES:")
                            for component, data in insights.items():
                                impact = data['impact_score']
                                if impact > 0.1:
                                    status = "ğŸ”´ CRÃTICO"
                                elif impact > 0.05:
                                    status = "ğŸŸ¡ IMPORTANTE"
                                else:
                                    status = "ğŸŸ¢ MENOR"
                                
                                print(f"   {component}: {status} (impacto: {impact:.3f})")
                        
                        # Generar visualizaciÃ³n
                        viz_path = runner.generate_visualization(results)
                        
                        print(f"\nğŸ“ ARCHIVOS GENERADOS:")
                        print(f"   ğŸ“Š VisualizaciÃ³n: {viz_path}")
                        print(f"   ğŸ“‹ Reporte JSON: {results.get('results_path', 'N/A')}")
                        
                        print("\nğŸ¯ RECOMENDACIÃ“N FINAL:")
                        if best_overall.get('by_efficiency'):
                            eff_best = best_overall['by_efficiency']
                            print(f"   Para mejor eficiencia: {eff_best['variant']}")
                        
                    else:
                        error = results.get('error', 'Error desconocido')
                        print(f"\nâŒ Experimentos fallaron: {error}")
                        
                except Exception as e:
                    print(f"\nâŒ Error durante experimentos: {e}")
                    print("ğŸ’¡ Tip: AsegÃºrate de que el modelo sea compatible")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
        except Exception as e:
            self.display.show_error(f"Error en experimentos de ablaciÃ³n: {e}")
        
        self.display.pause_for_user()
    
    def _run_test_suite(self) -> None:
        """Ejecutar suite de tests del MÃ³dulo 2."""
        print("\nğŸ§ª SUITE DE TESTS MÃ“DULO 2")
        print("=" * 60)
        print("ğŸ¯ SISTEMA COMPLETO DE VALIDACIÃ“N Y DEMOSTRACIÃ“N")
        print("=" * 60)
        print()
        print("Esta suite ejecutarÃ¡ automÃ¡ticamente:")
        print("â€¢ ğŸ“š Entrenamiento de modelo de prueba (3 Ã©pocas)")
        print("â€¢ ğŸ“ˆ AnÃ¡lisis completo de gradientes")  
        print("â€¢ ğŸ”ï¸ AnÃ¡lisis del paisaje de pÃ©rdida")
        print("â€¢ ğŸ§ª Experimentos de ablaciÃ³n")
        print("â€¢ ğŸ¥ CirugÃ­a de emergencia de gates")
        print("â€¢ ğŸ“‹ GeneraciÃ³n de reportes consolidados")
        print()
        print("ğŸ•’ Tiempo estimado: 10-20 minutos")
        print("ğŸ“ Se generarÃ¡n logs y reportes detallados")
        print()
        
        # MenÃº de opciones de testing
        print("ğŸ“‹ OPCIONES DE TESTING DISPONIBLES:")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ 1. ğŸš€ Demo RÃ¡pido     â”‚ Tests bÃ¡sicos (~5 min)     â”‚")
        print("â”‚ 2. ğŸ”¬ ValidaciÃ³n Full â”‚ Todos los tests (~20 min)  â”‚")  
        print("â”‚ 3. ğŸ¯ Tests Selectivosâ”‚ Elegir tests especÃ­ficos   â”‚")
        print("â”‚ 4. ğŸ“Š Tests por Bloqueâ”‚ Ejecutar por categorÃ­as    â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        print()
        
        choice = input("Selecciona modalidad (1-4): ").strip()
        
        if choice == "1":
            self._run_quick_demo()
        elif choice == "2":
            self._run_full_validation()
        elif choice == "3":
            self._run_selective_tests()
        elif choice == "4":
            self._run_block_tests()
        else:
            print("âŒ OpciÃ³n invÃ¡lida")
            self.display.pause_for_user()
            return
    
    def _run_quick_demo(self) -> None:
        """Ejecutar demo rÃ¡pido del sistema."""
        print("\nğŸš€ DEMO RÃPIDO - VALIDACIÃ“N BÃSICA")
        print("=" * 50)
        print("Ejecutando: Entrenamiento â†’ Gradientes â†’ CirugÃ­a")
        print("â±ï¸ Tiempo estimado: 5 minutos")
        print()
        
        confirm = input("Â¿Proceder con demo rÃ¡pido? (s/N): ").lower().strip()
        
        if confirm in ('s', 'si', 'y', 'yes'):
            try:
                from testing.module2_test_suite import run_quick_demo
                
                print("\nğŸ¬ INICIANDO DEMO...")
                results = run_quick_demo()
                
                self._show_test_results(results, "Demo RÃ¡pido")
                
            except Exception as e:
                print(f"\nâŒ Error en demo: {e}")
        else:
            print("âŒ Demo cancelado")
        
        self.display.pause_for_user()
    
    def _run_full_validation(self) -> None:
        """Ejecutar validaciÃ³n completa del sistema."""
        print("\nğŸ”¬ VALIDACIÃ“N COMPLETA - TODOS LOS COMPONENTES")
        print("=" * 60)
        print("Ejecutando TODOS los tests del MÃ³dulo 2:")
        print("â€¢ Entrenamiento + AnÃ¡lisis + AblaciÃ³n + CirugÃ­a + Reportes")
        print("â±ï¸ Tiempo estimado: 15-25 minutos")
        print()
        
        confirm = input("Â¿Proceder con validaciÃ³n completa? (s/N): ").lower().strip()
        
        if confirm in ('s', 'si', 'y', 'yes'):
            try:
                from testing.module2_test_suite import run_full_validation
                
                print("\nğŸ”¬ INICIANDO VALIDACIÃ“N COMPLETA...")
                results = run_full_validation()
                
                self._show_test_results(results, "ValidaciÃ³n Completa")
                
            except Exception as e:
                print(f"\nâŒ Error en validaciÃ³n: {e}")
        else:
            print("âŒ ValidaciÃ³n cancelada")
        
        self.display.pause_for_user()
    
    def _run_selective_tests(self) -> None:
        """Ejecutar tests especÃ­ficos seleccionados por el usuario."""
        print("\nğŸ¯ TESTS SELECTIVOS - SELECCIÃ“N PERSONALIZADA")
        print("=" * 55)
        
        available_tests = [
            ('training', 'ğŸ“š Entrenamiento de Modelo'),
            ('gradient_analysis', 'ğŸ“ˆ AnÃ¡lisis de Gradientes'),
            ('minima_analysis', 'ğŸ”ï¸ AnÃ¡lisis de Minima'),
            ('ablation_experiments', 'ğŸ§ª Experimentos de AblaciÃ³n'),
            ('emergency_surgery', 'ğŸ¥ CirugÃ­a de Emergencia'),
            ('report_generation', 'ğŸ“‹ GeneraciÃ³n de Reportes')
        ]
        
        print("Selecciona los tests a ejecutar (nÃºmeros separados por comas):")
        for i, (test_key, test_name) in enumerate(available_tests, 1):
            print(f"{i}. {test_name}")
        
        selection = input("\nSelecciÃ³n (ej: 1,2,5): ").strip()
        
        try:
            selected_indices = [int(x.strip()) for x in selection.split(',')]
            selected_tests = [available_tests[i-1][0] for i in selected_indices 
                            if 1 <= i <= len(available_tests)]
            
            if selected_tests:
                print(f"\nâœ… Tests seleccionados: {len(selected_tests)}")
                for test_key in selected_tests:
                    test_name = dict(available_tests)[test_key]
                    print(f"   â€¢ {test_name}")
                
                confirm = input("\nÂ¿Ejecutar tests seleccionados? (s/N): ").lower().strip()
                
                if confirm in ('s', 'si', 'y', 'yes'):
                    from testing.module2_test_suite import run_selected_tests
                    
                    print("\nğŸ¯ EJECUTANDO TESTS SELECCIONADOS...")
                    results = run_selected_tests(selected_tests)
                    
                    self._show_test_results(results, "Tests Selectivos")
                else:
                    print("âŒ EjecuciÃ³n cancelada")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Formato de selecciÃ³n invÃ¡lido")
        except Exception as e:
            print(f"âŒ Error ejecutando tests: {e}")
        
        self.display.pause_for_user()
    
    def _run_block_tests(self) -> None:
        """Ejecutar tests organizados por bloques funcionales."""
        print("\nğŸ“Š TESTS POR BLOQUES - CATEGORÃAS FUNCIONALES")
        print("=" * 55)
        
        test_blocks = {
            'core': {
                'name': 'ğŸ¯ CORE (Entrenamiento + CirugÃ­a)',
                'tests': ['training', 'emergency_surgery'],
                'description': 'Funcionalidades bÃ¡sicas del sistema'
            },
            'analysis': {
                'name': 'ğŸ”¬ ANÃLISIS (Gradientes + Minima)',
                'tests': ['gradient_analysis', 'minima_analysis'],
                'description': 'Suite de anÃ¡lisis profundo'
            },
            'advanced': {
                'name': 'ğŸ§ª AVANZADO (AblaciÃ³n + Reportes)',
                'tests': ['ablation_experiments', 'report_generation'],
                'description': 'Funcionalidades experimentales'
            }
        }
        
        print("Selecciona bloque de tests:")
        for i, (block_key, block_info) in enumerate(test_blocks.items(), 1):
            print(f"{i}. {block_info['name']}")
            print(f"   {block_info['description']}")
            print(f"   Tests: {len(block_info['tests'])}")
        
        choice = input("\nSelecciona bloque (1-3): ").strip()
        
        try:
            if choice == "1":
                selected_block = test_blocks['core']
            elif choice == "2":
                selected_block = test_blocks['analysis']
            elif choice == "3":
                selected_block = test_blocks['advanced']
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                self.display.pause_for_user()
                return
            
            print(f"\nâœ… Bloque seleccionado: {selected_block['name']}")
            print(f"ğŸ“‹ Tests incluidos: {len(selected_block['tests'])}")
            
            confirm = input("Â¿Ejecutar este bloque? (s/N): ").lower().strip()
            
            if confirm in ('s', 'si', 'y', 'yes'):
                from testing.module2_test_suite import run_selected_tests
                
                print(f"\nğŸ“Š EJECUTANDO BLOQUE: {selected_block['name']}")
                results = run_selected_tests(selected_block['tests'])
                
                self._show_test_results(results, f"Bloque {selected_block['name']}")
            else:
                print("âŒ EjecuciÃ³n cancelada")
                
        except Exception as e:
            print(f"âŒ Error ejecutando bloque: {e}")
        
        self.display.pause_for_user()
    
    def _show_test_results(self, results: Dict, test_type: str) -> None:
        """Mostrar resultados consolidados de los tests."""
        print(f"\nğŸ‰ {test_type.upper()} COMPLETADO")
        print("=" * 60)
        
        if results.get('success'):
            stats = results.get('summary_statistics', {})
            print(f"âœ… Ã‰XITO TOTAL")
            print(f"ğŸ“Š Tests ejecutados: {stats.get('successful_tests', 0)}/{stats.get('total_tests', 0)}")
            print(f"â±ï¸ Tiempo total: {stats.get('total_execution_time', 0):.2f} segundos")
            print(f"ğŸ“ˆ Tasa de Ã©xito: {stats.get('success_rate', 0):.1%}")
            
            # Mostrar resultados individuales destacados
            individual_results = results.get('individual_test_results', {})
            
            if 'training' in individual_results:
                training = individual_results['training']
                if training.get('status') == 'SUCCESS':
                    print(f"\nğŸ¯ MODELO ENTRENADO:")
                    print(f"   ParÃ¡metros: {training.get('parameters', 'N/A'):,}")
                    print(f"   Ã‰pocas: {training.get('epochs_trained', 'N/A')}")
            
            if 'gradient_analysis' in individual_results:
                gradient = individual_results['gradient_analysis']
                if gradient.get('status') == 'SUCCESS':
                    print(f"\nğŸ“ˆ ANÃLISIS DE GRADIENTES:")
                    vanishing = "SÃ­" if gradient.get('has_vanishing') else "No"
                    exploding = "SÃ­" if gradient.get('has_exploding') else "No"
                    print(f"   Vanishing: {vanishing}")
                    print(f"   Exploding: {exploding}")
            
            if 'emergency_surgery' in individual_results:
                surgery = individual_results['emergency_surgery']
                if surgery.get('status') == 'SUCCESS':
                    success = "Exitosa" if surgery.get('surgery_successful') else "Fallo"
                    print(f"\nğŸ¥ CIRUGÃA: {success}")
            
        else:
            print(f"âŒ ALGUNOS TESTS FALLARON")
            failed_tests = [name for name, result in results.get('individual_test_results', {}).items() 
                          if result.get('status') != 'SUCCESS']
            print(f"ğŸ“‹ Tests fallidos: {', '.join(failed_tests)}")
        
        # InformaciÃ³n de archivos generados
        metadata = results.get('test_suite_metadata', {})
        log_file = metadata.get('log_file')
        if log_file:
            print(f"\nğŸ“ ARCHIVOS GENERADOS:")
            print(f"   ğŸ“ Log detallado: {log_file}")
            print(f"   ğŸ“Š Reportes JSON/TXT en directorio actual")
        
        print("\nğŸ’¡ Los reportes contienen anÃ¡lisis detallado de todos los tests")
    
    def _view_logs_and_files(self) -> None:
        """Ver logs y archivos generados por el sistema."""
        print("\nğŸ“ EXPLORADOR DE LOGS Y ARCHIVOS GENERADOS")
        print("=" * 60)
        
        try:
            from utils.file_viewer import FileViewer, LogInspector
            
            viewer = FileViewer()
            inspector = LogInspector()
            
            # Mostrar resumen de archivos
            summary = viewer.display_file_summary()
            print(summary)
            
            print("\nğŸ“‹ OPCIONES DE VISUALIZACIÃ“N:")
            print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("â”‚ 1. ğŸ“„ Ver log mÃ¡s reciente                     â”‚")
            print("â”‚ 2. ğŸ“Š Inspeccionar reporte especÃ­fico          â”‚")
            print("â”‚ 3. ğŸ” Buscar por tipo de archivo              â”‚")
            print("â”‚ 4. ğŸ“ˆ Resumen de todos los logs               â”‚")
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            print()
            
            choice = input("Selecciona opciÃ³n (1-4): ").strip()
            
            if choice == "1":
                self._view_latest_log(inspector)
            elif choice == "2":
                self._inspect_specific_report(viewer)
            elif choice == "3":
                self._browse_by_file_type(viewer)
            elif choice == "4":
                self._show_logs_summary(inspector)
            else:
                print("âŒ OpciÃ³n invÃ¡lida")
                
        except ImportError:
            print("âŒ Sistema de visualizaciÃ³n no disponible")
            print("ğŸ’¡ Instala las dependencias necesarias")
        except Exception as e:
            print(f"âŒ Error accediendo archivos: {e}")
        
        self.display.pause_for_user()
    
    def _view_latest_log(self, inspector: 'LogInspector') -> None:
        """Ver el log mÃ¡s reciente."""
        print("\nğŸ“„ LOG MÃS RECIENTE")
        print("-" * 40)
        
        latest_logs = inspector.find_latest_logs()
        
        if not latest_logs:
            print("ğŸ“­ No se encontraron logs")
            return
        
        latest = latest_logs[0]
        print(f"ğŸ“ Archivo: {latest['name']}")
        print(f"ğŸ•’ Fecha: {latest['modified_human']}")
        print(f"ğŸ“ TamaÃ±o: {latest['size_human']}")
        
        if 'log_type' in latest:
            print(f"ğŸ·ï¸ Tipo: {latest['log_type']}")
        
        print("\n" + "="*50)
        
        log_data = inspector.viewer.read_log_file(latest['path'], tail_lines=50)
        
        if log_data['success']:
            print("ğŸ“‹ ÃšLTIMAS 50 LÃNEAS:")
            print("-" * 30)
            print(log_data['content'])
            
            analysis = log_data['analysis']
            print(f"\nğŸ“Š ESTADÃSTICAS:")
            print(f"   Total lÃ­neas: {analysis['total_lines']}")
            print(f"   âŒ Errores: {len(analysis['errors'])}")
            print(f"   âš ï¸  Warnings: {len(analysis['warnings'])}")
            print(f"   âœ… Ã‰xitos: {len(analysis['success'])}")
        else:
            print(f"âŒ Error leyendo log: {log_data['error']}")
    
    def _inspect_specific_report(self, viewer: 'FileViewer') -> None:
        """Inspeccionar un reporte especÃ­fico."""
        print("\nğŸ“Š INSPECTOR DE REPORTES")
        print("-" * 40)
        
        files = viewer.scan_generated_files()
        reports = files.get('reports', [])
        
        if not reports:
            print("ğŸ“­ No se encontraron reportes")
            return
        
        print("ğŸ“‹ Reportes disponibles:")
        for i, report in enumerate(reports[:10], 1):
            report_type = report.get('report_type', 'Unknown')
            print(f"{i}. {report['name']} - {report_type} ({report['modified_human']})")
        
        try:
            selection = input(f"\nSelecciona reporte (1-{min(10, len(reports))}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(reports):
                selected = reports[idx]
                self._show_report_details(selected['path'])
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
    
    def _show_report_details(self, report_path: str) -> None:
        """Mostrar detalles de un reporte."""
        print(f"\nğŸ“Š DETALLES DEL REPORTE")
        print("=" * 50)
        
        try:
            if report_path.endswith('.json'):
                with open(report_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Mostrar informaciÃ³n estructurada segÃºn el tipo
                if 'test_suite_metadata' in data:
                    self._show_test_report_details(data)
                elif 'sharpness_classification' in data:
                    self._show_minima_report_details(data)
                elif 'collapse_analysis' in data:
                    self._show_gradient_report_details(data)
                else:
                    # Mostrar JSON genÃ©rico
                    import json as json_module
                    print(json_module.dumps(data, indent=2, ensure_ascii=False))
            else:
                # Archivo de texto
                with open(report_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                print(content)
                
        except Exception as e:
            print(f"âŒ Error leyendo reporte: {e}")
    
    def _show_test_report_details(self, data: Dict) -> None:
        """Mostrar detalles especÃ­ficos de reporte de tests."""
        metadata = data['test_suite_metadata']
        stats = data['summary_statistics']
        
        print("ğŸ§ª REPORTE DE TESTS")
        print(f"ğŸ•’ Ejecutado: {metadata['timestamp']}")
        print(f"â±ï¸ DuraciÃ³n: {stats['total_execution_time']:.2f}s")
        print(f"ğŸ“Š Tests: {stats['successful_tests']}/{stats['total_tests']}")
        print(f"ğŸ“ˆ Ã‰xito: {stats['success_rate']:.1%}")
        
        print(f"\nğŸ“‹ RESULTADOS INDIVIDUALES:")
        for test_name, result in data['individual_test_results'].items():
            status = "âœ…" if result['status'] == 'SUCCESS' else "âŒ"
            print(f"  {status} {test_name.replace('_', ' ').title()}")
            
            if result['status'] == 'SUCCESS' and 'total_time' in result:
                print(f"      â±ï¸ {result['total_time']:.2f}s")
    
    def _show_minima_report_details(self, data: Dict) -> None:
        """Mostrar detalles especÃ­ficos de anÃ¡lisis de minima."""
        classification = data['sharpness_classification']
        
        print("ğŸ”ï¸ ANÃLISIS DE PAISAJE DE PÃ‰RDIDA")
        print(f"ğŸ·ï¸ CategorÃ­a: {classification['category']}")
        print(f"ğŸ“ˆ Sharpness: {classification['overall_sharpness']:.4f}")
        print(f"ğŸ’¡ {classification['interpretation']}")
        
        if 'recommendations' in data:
            print(f"\nğŸ’¡ RECOMENDACIONES:")
            for rec in data['recommendations']:
                print(f"  â€¢ {rec}")
    
    def _show_gradient_report_details(self, data: Dict) -> None:
        """Mostrar detalles especÃ­ficos de anÃ¡lisis de gradientes."""
        collapse = data.get('collapse_analysis', {})
        pascanu = data.get('pascanu_analysis', {})
        
        print("ğŸ“ˆ ANÃLISIS DE GRADIENTES")
        print(f"ğŸ“Š Batches analizados: {data['analysis_metadata']['batches_analyzed']}")
        print(f"â±ï¸ DuraciÃ³n: {data['analysis_metadata']['duration_minutes']:.2f} min")
        
        print(f"\nğŸ“‰ DIAGNÃ“STICO:")
        print(f"  Vanishing: {'SÃ­' if pascanu.get('has_vanishing') else 'No'}")
        print(f"  Exploding: {'SÃ­' if pascanu.get('has_exploding') else 'No'}")
        
        if collapse.get('earliest_collapse', -1) >= 0:
            print(f"  ğŸ”´ Colapso en batch: {collapse['earliest_collapse']}")
    
    def _browse_by_file_type(self, viewer: 'FileViewer') -> None:
        """Navegar archivos por tipo."""
        print("\nğŸ” NAVEGADOR POR TIPO DE ARCHIVO")
        print("-" * 40)
        
        files = viewer.scan_generated_files()
        
        print("ğŸ“‚ CategorÃ­as disponibles:")
        categories = list(files.keys())
        for i, category in enumerate(categories, 1):
            count = len(files[category])
            category_display = {
                'logs': 'ğŸ“ Logs',
                'reports': 'ğŸ“Š Reportes', 
                'visualizations': 'ğŸ“ˆ Visualizaciones',
                'models': 'ğŸ§  Modelos'
            }.get(category, category)
            
            print(f"{i}. {category_display} ({count} archivos)")
        
        try:
            selection = input(f"\nSelecciona categorÃ­a (1-{len(categories)}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(categories):
                selected_category = categories[idx]
                self._show_category_files(files[selected_category], selected_category)
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
    
    def _show_category_files(self, file_list: List[Dict], category: str) -> None:
        """Mostrar archivos de una categorÃ­a especÃ­fica."""
        category_display = {
            'logs': 'ğŸ“ LOGS',
            'reports': 'ğŸ“Š REPORTES', 
            'visualizations': 'ğŸ“ˆ VISUALIZACIONES',
            'models': 'ğŸ§  MODELOS'
        }.get(category, category.upper())
        
        print(f"\n{category_display}")
        print("=" * 50)
        
        if not file_list:
            print("ğŸ“­ No hay archivos en esta categorÃ­a")
            return
        
        for i, file_info in enumerate(file_list, 1):
            print(f"{i}. ğŸ“„ {file_info['name']}")
            print(f"   ğŸ“ {file_info['size_human']} - ğŸ•’ {file_info['modified_human']}")
            
            # InformaciÃ³n especÃ­fica por tipo
            if category == 'logs' and 'log_type' in file_info:
                print(f"   ğŸ·ï¸ {file_info['log_type']}")
            elif category == 'reports' and 'report_type' in file_info:
                print(f"   ğŸ“Š {file_info['report_type']}")
            elif category == 'visualizations' and 'viz_type' in file_info:
                print(f"   ğŸ“ˆ {file_info['viz_type']}")
            elif category == 'models' and 'model_type' in file_info:
                print(f"   ğŸ§  {file_info['model_type']}")
            
            print()
    
    def _show_logs_summary(self, inspector: 'LogInspector') -> None:
        """Mostrar resumen de todos los logs."""
        print("\nğŸ“ˆ RESUMEN DE LOGS DEL SISTEMA")
        print("=" * 50)
        
        recent_logs = inspector.find_latest_logs()
        
        if not recent_logs:
            print("ğŸ“­ No se encontraron logs")
            return
        
        total_errors = 0
        total_warnings = 0
        total_success = 0
        
        print("ğŸ“Š LOGS RECIENTES (mÃ¡ximo 10):")
        print("-" * 40)
        
        for log_info in recent_logs:
            print(f"ğŸ“ {log_info['name']}")
            print(f"   ğŸ•’ {log_info['modified_human']}")
            
            if 'errors' in log_info:
                errors = log_info['errors']
                warnings = log_info.get('warnings', 0)
                success = log_info.get('success_markers', 0)
                
                print(f"   ğŸ“Š âŒ {errors} | âš ï¸ {warnings} | âœ… {success}")
                
                total_errors += errors
                total_warnings += warnings  
                total_success += success
            
            print()
        
        print("ğŸ“ˆ ESTADÃSTICAS TOTALES:")
        print(f"   âŒ Total errores: {total_errors}")
        print(f"   âš ï¸ Total warnings: {total_warnings}")
        print(f"   âœ… Total Ã©xitos: {total_success}")
        
        if total_errors == 0:
            print("\nğŸ‰ Â¡Sistema funcionando sin errores!")
        elif total_errors < total_success:
            print(f"\nâš ï¸ Sistema mayormente estable ({total_success-total_errors} mÃ¡s Ã©xitos que errores)")
        else:
            print(f"\nğŸ”´ AtenciÃ³n: {total_errors} errores detectados")
    
    def _explore_visualizations(self) -> None:
        """Explorar visualizaciones y grÃ¡ficos generados."""
        print("\nğŸ“ˆ EXPLORADOR DE VISUALIZACIONES Y GRÃFICOS")
        print("=" * 60)
        
        try:
            from utils.file_viewer import FileViewer
            
            viewer = FileViewer()
            files = viewer.scan_generated_files()
            visualizations = files.get('visualizations', [])
            
            if not visualizations:
                print("ğŸ“­ No se encontraron visualizaciones")
                print("ğŸ’¡ Ejecuta anÃ¡lisis para generar grÃ¡ficos:")
                print("   â€¢ python robo_poet.py --analyze modelo.keras")
                print("   â€¢ python robo_poet.py --minima modelo.keras")
                print("   â€¢ python robo_poet.py --test quick")
                self.display.pause_for_user()
                return
            
            print(f"ğŸ“Š VISUALIZACIONES DISPONIBLES ({len(visualizations)}):")
            print("=" * 50)
            
            for i, viz in enumerate(visualizations, 1):
                viz_type = viz.get('viz_type', 'Unknown')
                print(f"{i}. ğŸ“ˆ {viz['name']}")
                print(f"   ğŸ·ï¸ Tipo: {viz_type}")
                print(f"   ğŸ“ {viz['size_human']} - ğŸ•’ {viz['modified_human']}")
                print()
            
            print("ğŸ“‹ OPCIONES:")
            print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("â”‚ 1. ğŸ“„ Ver informaciÃ³n detallada de grÃ¡fico     â”‚")
            print("â”‚ 2. ğŸ—‚ï¸  Organizar por tipo de anÃ¡lisis          â”‚")
            print("â”‚ 3. ğŸ’» Mostrar comandos para abrir imÃ¡genes     â”‚")
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            print()
            
            choice = input("Selecciona opciÃ³n (1-3): ").strip()
            
            if choice == "1":
                self._show_visualization_details(visualizations)
            elif choice == "2":
                self._organize_visualizations_by_type(visualizations)
            elif choice == "3":
                self._show_image_open_commands(visualizations)
            else:
                print("âŒ OpciÃ³n invÃ¡lida")
                
        except ImportError:
            print("âŒ Sistema de visualizaciÃ³n no disponible")
        except Exception as e:
            print(f"âŒ Error accediendo visualizaciones: {e}")
        
        self.display.pause_for_user()
    
    def _show_visualization_details(self, visualizations: List[Dict]) -> None:
        """Mostrar detalles de una visualizaciÃ³n especÃ­fica."""
        print("\nğŸ“„ DETALLES DE VISUALIZACIÃ“N")
        print("-" * 40)
        
        try:
            selection = input(f"Selecciona visualizaciÃ³n (1-{len(visualizations)}): ").strip()
            idx = int(selection) - 1
            
            if 0 <= idx < len(visualizations):
                viz = visualizations[idx]
                
                print(f"ğŸ“ˆ ARCHIVO: {viz['name']}")
                print(f"ğŸ—‚ï¸ Ruta: {viz['path']}")
                print(f"ğŸ“ TamaÃ±o: {viz['size_human']}")
                print(f"ğŸ•’ Creado: {viz['modified_human']}")
                
                # InformaciÃ³n especÃ­fica por tipo
                from utils.file_viewer import FileViewer
                viewer = FileViewer()
                viz_info = viewer.get_visualization_info(viz['path'])
                
                if viz_info['success']:
                    print(f"ğŸ·ï¸ Tipo: {viz_info.get('type', 'Unknown')}")
                    print(f"ğŸ“‹ DescripciÃ³n: {viz_info.get('description', 'N/A')}")
                    
                    if 'contains' in viz_info:
                        print(f"ğŸ“Š Contiene:")
                        for item in viz_info['contains']:
                            print(f"   â€¢ {item}")
                
                # Comando para abrir
                print(f"\nğŸ’» COMANDOS PARA ABRIR:")
                if os.name == 'nt':  # Windows
                    print(f"   start {viz['path']}")
                else:  # Linux/Mac
                    print(f"   xdg-open {viz['path']}")
                    print(f"   eog {viz['path']}  # GNOME")
                    print(f"   feh {viz['path']}  # Lightweight")
            else:
                print("âŒ SelecciÃ³n invÃ¡lida")
                
        except ValueError:
            print("âŒ Entrada invÃ¡lida")
    
    def _organize_visualizations_by_type(self, visualizations: List[Dict]) -> None:
        """Organizar visualizaciones por tipo de anÃ¡lisis."""
        print("\nğŸ—‚ï¸ VISUALIZACIONES POR TIPO")
        print("=" * 50)
        
        # Agrupar por tipo
        by_type = {}
        for viz in visualizations:
            viz_type = viz.get('viz_type', 'Unknown')
            if viz_type not in by_type:
                by_type[viz_type] = []
            by_type[viz_type].append(viz)
        
        for viz_type, viz_list in by_type.items():
            print(f"\nğŸ“ˆ {viz_type.upper()} ({len(viz_list)} archivos):")
            print("-" * 40)
            
            for viz in viz_list:
                print(f"  ğŸ“„ {viz['name']} - {viz['modified_human']}")
    
    def _show_image_open_commands(self, visualizations: List[Dict]) -> None:
        """Mostrar comandos para abrir todas las imÃ¡genes."""
        print("\nğŸ’» COMANDOS PARA ABRIR IMÃGENES")
        print("=" * 50)
        
        if os.name == 'nt':  # Windows
            print("ğŸªŸ COMANDOS WINDOWS:")
            for viz in visualizations:
                print(f"start \"{viz['path']}\"")
        else:  # Linux/Mac
            print("ğŸ§ COMANDOS LINUX:")
            for viz in visualizations:
                print(f"xdg-open \"{viz['path']}\"")
                
            print(f"\nğŸ–¼ï¸ ABRIR TODAS DE UNA VEZ:")
            paths = ' '.join(f'"{viz["path"]}"' for viz in visualizations)
            print(f"xdg-open {paths}")
    
    def _clean_all_models(self) -> None:
        """Clean all models with enhanced confirmation."""
        print("\nğŸ§¹ LIMPIAR TODOS LOS MODELOS")
        print("=" * 50)
        
        models = self.file_manager.list_available_models()
        if not models:
            print("âœ… No hay modelos para limpiar")
            self.display.pause_for_user()
            return
        
        print(f"ğŸ“Š Se encontraron {len(models)} modelos")
        
        # Calculate total size
        total_size = 0
        for model_path in models:
            total_size += Path(model_path).stat().st_size
        
        total_mb = total_size / (1024 * 1024)
        print(f"ğŸ’¾ Espacio total a liberar: {total_mb:.1f} MB")
        
        self.display.show_warning(
            "Esta acciÃ³n eliminarÃ¡ PERMANENTEMENTE todos los modelos entrenados.\n"
            "   No podrÃ¡s usar FASE 2 (GeneraciÃ³n) hasta entrenar nuevos modelos."
        )
        
        confirm = input("\nğŸ—‘ï¸ Â¿Confirmar limpieza? (escribe 'ELIMINAR' para confirmar): ").strip()
        
        if confirm != 'ELIMINAR':
            print("âŒ Limpieza cancelada")
            self.display.pause_for_user()
            return
        
        # Perform cleanup
        results = self.file_manager.clean_all_models()
        self.display.format_cleanup_results(results)
        self.display.pause_for_user()
    
    def _run_attention_demos(self) -> None:
        """Ejecutar demos y validaciÃ³n del mecanismo de atenciÃ³n."""
        print("\nğŸ¯ ATTENTION MECHANISM DEMO & VALIDATION")
        print("=" * 60)
        print("ğŸ­ Target: Beat LSTM baseline (val_loss = 6.5)")
        print("ğŸ“ Implementation: Scaled Dot-Product Attention")
        print()
        
        print("ğŸ”¬ OPCIONES DISPONIBLES:")
        print("1. ğŸ“– Conceptual Demo (sin dependencias)")
        print("2. ğŸ§ª Validation Suite (requiere TensorFlow)")
        print("3. ğŸ“‹ Architecture Documentation")
        print("4. ğŸ”™ Volver al menÃº principal")
        print()
        
        try:
            choice = input("ğŸ¯ Selecciona una opciÃ³n (1-4): ").strip()
            
            if choice == '1':
                print("\nğŸš€ Ejecutando demo conceptual...")
                import subprocess
                result = subprocess.run([
                    'python', 'demos/demo_attention_concept.py'
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(result.stdout)
                else:
                    print("âš ï¸ Demo conceptual no disponible (dependencias faltantes)")
                    print("ğŸ’¡ El demo muestra la arquitectura y validaciones matemÃ¡ticas")
                    
            elif choice == '2':
                print("\nğŸ§ª Ejecutando suite de validaciÃ³n...")
                try:
                    import sys
                    sys.path.insert(0, 'src')
                    from attention.attention_validator import AttentionValidator
                    
                    validator = AttentionValidator(sequence_length=128, d_model=256)
                    results = validator.run_full_validation()
                    
                    if results['summary']['overall_status'] == 'PASSED':
                        print("ğŸ‰ Â¡Attention mechanism completamente validado!")
                    else:
                        print("âš ï¸ ValidaciÃ³n parcial - revisar logs")
                        
                except ImportError:
                    print("âŒ TensorFlow no disponible")
                    print("ğŸ’¡ Instalar con: pip install tensorflow numpy")
                    
            elif choice == '3':
                print("\nğŸ“š ATTENTION ARCHITECTURE DOCUMENTATION")
                print("=" * 50)
                print("ğŸ“ DocumentaciÃ³n disponible:")
                print("   ğŸ“– docs/technical/ATTENTION_IMPLEMENTATION_SUMMARY.md")
                print("   ğŸ”§ src/attention/scaled_dot_product_attention.py")
                print("   ğŸ§ª src/attention/attention_validator.py")
                print()
                print("ğŸ¯ CaracterÃ­sticas clave:")
                print("   âœ… Pure TensorFlow (no pre-built layers)")
                print("   âœ… Shape assertions y gradient tracking")
                print("   âœ… Causal masking para autoregressive generation")
                print("   âœ… Dropout despuÃ©s de softmax")
                print("   âœ… Optimizado para sequence_length=128, d_model=256")
                
            elif choice == '4':
                return
            else:
                print("âŒ OpciÃ³n invÃ¡lida")
                
        except Exception as e:
            print(f"âŒ Error en attention demos: {e}")
        
        input("\nğŸ“– Presiona Enter para continuar...")
    
    def _run_dataset_preprocessing(self) -> None:
        """Ejecutar pipeline de preprocesamiento de dataset."""
        print("\nğŸ—ï¸ DATASET PREPROCESSING PIPELINE")
        print("=" * 60)
        print("ğŸ¯ Objetivo: Unificar corpus disperso para mejor convergencia")
        print("ğŸ­ Corpus actual: Shakespeare + Alice (4 archivos)")
        print()
        
        print("ğŸ”§ OPCIONES DE PREPROCESAMIENTO:")
        print("1. ğŸš€ Ejecutar Pipeline Completo (Recomendado)")
        print("2. ğŸ“Š Analizar Corpus Actual")
        print("3. ğŸ” Validar Dataset Procesado")
        print("4. ğŸ”™ Volver al menÃº principal")
        print()
        
        try:
            choice = input("ğŸ¯ Selecciona una opciÃ³n (1-4): ").strip()
            
            if choice == '1':
                print("\nğŸš€ EJECUTANDO PIPELINE COMPLETO...")
                print("=" * 50)
                
                try:
                    import sys
                    sys.path.insert(0, 'src')
                    from data.dataset_preprocessor import DatasetPreprocessor, PreprocessingConfig
                    
                    # ConfiguraciÃ³n optimizada para Shakespeare & Alice
                    config = PreprocessingConfig(
                        preserve_case=True,
                        preserve_verse_structure=True,
                        max_vocab_size=15000,
                        remove_rare_words=True,
                        rare_word_threshold=2
                    )
                    
                    preprocessor = DatasetPreprocessor(config)
                    result = preprocessor.process_full_pipeline("corpus")
                    
                    if result['success']:
                        print("\nğŸ‰ PIPELINE COMPLETADO EXITOSAMENTE")
                        print(f"ğŸ“š Documentos: {result['documents_loaded']}")
                        print(f"ğŸ“ Vocabulario: {result['vocabulary_size']:,}")
                        print(f"ğŸ“Š Corpus: {result['corpus_size']:,} chars")
                        print(f"â±ï¸ Tiempo: {result['processing_time']:.2f}s")
                        print()
                        print("ğŸ’¡ Dataset unificado disponible en data/processed/")
                        print("ğŸš€ Ahora entrena con: python robo_poet.py --model unified_model")
                    else:
                        print(f"âŒ Error en pipeline: {result.get('error', 'Unknown')}")
                        
                except ImportError as e:
                    print(f"âŒ Error de importaciÃ³n: {e}")
                    print("ğŸ’¡ Algunos mÃ³dulos requieren dependencias adicionales")
                    
            elif choice == '2':
                print("\nğŸ“Š ANÃLISIS DEL CORPUS ACTUAL")
                print("=" * 50)
                
                from pathlib import Path
                corpus_path = Path("corpus")
                
                if corpus_path.exists():
                    txt_files = list(corpus_path.glob("*.txt"))
                    
                    if txt_files:
                        print(f"âœ… Encontrados {len(txt_files)} archivos:")
                        
                        total_size = 0
                        for txt_file in sorted(txt_files):
                            size = txt_file.stat().st_size
                            total_size += size
                            
                            # AnÃ¡lisis bÃ¡sico del contenido
                            try:
                                with open(txt_file, 'r', encoding='utf-8') as f:
                                    content = f.read()[:1000]  # Primera muestra
                                
                                word_count = len(content.split())
                                
                                # Detectar tipo
                                if "shakespeare" in txt_file.name.lower() or "hamlet" in txt_file.name.lower():
                                    doc_type = "ğŸ­ Drama/Poetry"
                                elif "alice" in txt_file.name.lower():
                                    doc_type = "ğŸ“š Narrative"
                                else:
                                    doc_type = "ğŸ“– General"
                                
                                print(f"   {doc_type} {txt_file.name}: {size:,} bytes, ~{word_count*10:,} words")
                                
                            except Exception as e:
                                print(f"   âŒ {txt_file.name}: Error - {e}")
                        
                        print(f"\nğŸ“ˆ RESUMEN:")
                        print(f"   Total: {total_size:,} bytes ({total_size/1024:.1f} KB)")
                        print(f"   Problema: Archivos dispersos â†’ convergencia lenta")
                        print(f"   SoluciÃ³n: Unificar con marcadores de documento")
                        
                    else:
                        print("âŒ No se encontraron archivos .txt en corpus/")
                else:
                    print("âŒ Directorio corpus/ no encontrado")
                    
            elif choice == '3':
                print("\nğŸ” VALIDACIÃ“N DE DATASET PROCESADO")
                print("=" * 50)
                
                processed_dir = Path("data/processed")
                if processed_dir.exists():
                    files = list(processed_dir.glob("*.txt")) + list(processed_dir.glob("*.json"))
                    
                    if files:
                        print(f"âœ… Dataset procesado encontrado: {len(files)} archivos")
                        
                        for file_path in sorted(files):
                            size = file_path.stat().st_size
                            print(f"   ğŸ“„ {file_path.name}: {size:,} bytes")
                        
                        # Verificar splits
                        splits_dir = processed_dir / "splits"
                        if splits_dir.exists():
                            splits = list(splits_dir.glob("*.txt"))
                            print(f"   ğŸ“‚ Splits disponibles: {len(splits)}")
                            for split_file in splits:
                                print(f"     ğŸ“Š {split_file.name}")
                        
                        print("\nğŸ’¡ Dataset listo para usar con modelo unificado")
                        
                    else:
                        print("âŒ No se encontrÃ³ dataset procesado")
                        print("ğŸ’¡ Ejecuta primero la opciÃ³n 1 (Pipeline Completo)")
                else:
                    print("âŒ Directorio data/processed/ no encontrado")
                    print("ğŸ’¡ Ejecuta primero la opciÃ³n 1 (Pipeline Completo)")
                    
            elif choice == '4':
                return
            else:
                print("âŒ OpciÃ³n invÃ¡lida")
                
        except Exception as e:
            print(f"âŒ Error en preprocessing: {e}")
        
        input("\nğŸ“– Presiona Enter para continuar...")


def main():
    """Main entry point for the Robo-Poet Academic Framework."""
    parser = argparse.ArgumentParser(
        description="ğŸ“ Robo-Poet Academic Neural Text Generation Framework",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python robo_poet.py                                                  # Interfaz acadÃ©mica interactiva
  python robo_poet.py --model mi_modelo --epochs 20                   # Entrenamiento multi-corpus (usa corpus/)
  python robo_poet.py --generate mi_modelo.keras                      # GeneraciÃ³n directa
  python robo_poet.py --generate mi_modelo.keras --seed "The power" --temp 0.8
  python robo_poet.py --surgery modelo.keras                          # CirugÃ­a de gates saturados
  python robo_poet.py --analyze modelo.keras --batches 30             # AnÃ¡lisis de gradientes
  python robo_poet.py --minima modelo.keras --config fast             # AnÃ¡lisis de paisaje de pÃ©rdida
  python robo_poet.py --ablation modelo.keras --experiments all       # Experimentos de ablaciÃ³n
  python robo_poet.py --test quick                                    # Tests rÃ¡pidos del MÃ³dulo 2
  python robo_poet.py --test selective --test-selection training      # Tests especÃ­ficos

IMPORTANTE: El sistema ahora usa automÃ¡ticamente TODOS los archivos .txt en la carpeta 'corpus/'
            para entrenar modelos mÃ¡s ricos y diversos. Simplemente pon tus textos en corpus/
        """
    )
    
    # Training arguments - now uses multi-corpus automatically
    parser.add_argument('--epochs', type=int, default=20, help='NÃºmero de Ã©pocas (default: 20)')
    parser.add_argument('--model', help='Nombre del modelo a entrenar (usa automÃ¡ticamente corpus/)')
    
    # Generation arguments
    parser.add_argument('--generate', help='Modelo para generaciÃ³n de texto')
    parser.add_argument('--seed', default='The power of', help='Seed para generaciÃ³n (default: "The power of")')
    parser.add_argument('--temp', '--temperature', type=float, default=0.8, 
                       help='Temperature para generaciÃ³n (default: 0.8)')
    parser.add_argument('--length', type=int, default=200, help='Longitud de generaciÃ³n (default: 200)')
    
    # Analysis and repair arguments (NEW)
    parser.add_argument('--surgery', help='Aplicar cirugÃ­a de emergencia a modelo con gates saturados')
    parser.add_argument('--analyze', help='Analizar flujo de gradientes del modelo')
    parser.add_argument('--batches', type=int, default=30, help='Batches para anÃ¡lisis (default: 30)')
    parser.add_argument('--minima', help='Analizar paisaje de pÃ©rdida (sharp vs flat minima)')
    parser.add_argument('--config', choices=['fast', 'standard', 'deep'], default='standard',
                       help='ConfiguraciÃ³n de anÃ¡lisis de minima: fast/standard/deep (default: standard)')
    parser.add_argument('--ablation', help='Ejecutar experimentos de ablaciÃ³n sistemÃ¡tica')
    parser.add_argument('--experiments', choices=['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim', 'all'], 
                       default='lstm_units', help='Tipo de experimentos de ablaciÃ³n (default: lstm_units)')
    
    # Testing arguments (NEW)
    parser.add_argument('--test', choices=['quick', 'full', 'selective'], 
                       help='Ejecutar suite de tests del MÃ³dulo 2')
    parser.add_argument('--test-selection', nargs='+',
                       choices=['training', 'gradient_analysis', 'minima_analysis', 
                               'ablation_experiments', 'emergency_surgery', 'report_generation'],
                       help='Tests especÃ­ficos para modo selective')
    
    args = parser.parse_args()
    
    # Initialize orchestrator
    orchestrator = RoboPoetOrchestrator()
    
    try:
        # Surgery mode (NEW)
        if args.surgery:
            from hospital.emergency_gate_surgery import quick_surgery
            print("ğŸš¨ INICIANDO CIRUGÃA DE EMERGENCIA...")
            operated_model, report = quick_surgery(args.surgery)
            if operated_model:
                print("ğŸ‰ CirugÃ­a exitosa - modelo operado guardado")
                return 0
            else:
                print("âŒ CirugÃ­a fallÃ³")
                return 1
        
        # Gradient Analysis mode (NEW)
        elif args.analyze:
            from analysis.gradient_analyzer_lite import GradientAnalyzerLite
            print("ğŸ”¬ INICIANDO ANÃLISIS DE GRADIENTES...")
            analyzer = GradientAnalyzerLite(args.analyze)
            results = analyzer.run_complete_analysis(args.batches)
            if results:
                print("ğŸ‰ AnÃ¡lisis completo exitoso")
                return 0
            else:
                print("âŒ AnÃ¡lisis fallÃ³")
                return 1
        
        # Minima Analysis mode (NEW)
        elif args.minima:
            from analysis.minima_analyzer import analyze_model_sharpness
            print("ğŸ”ï¸ INICIANDO ANÃLISIS DE PAISAJE DE PÃ‰RDIDA...")
            
            # Configure analysis based on --config argument
            if args.config == 'fast':
                config = {
                    'num_directions': 20,
                    'num_samples': 30,
                    'hessian_samples': 10,
                    'save_plots': True
                }
                print("âš¡ ConfiguraciÃ³n rÃ¡pida")
            elif args.config == 'deep':
                config = {
                    'num_directions': 100,
                    'num_samples': 200,
                    'hessian_samples': 50,
                    'save_plots': True
                }
                print("ğŸ”¬ ConfiguraciÃ³n profunda")
            else:  # standard
                config = {
                    'num_directions': 50,
                    'num_samples': 100,
                    'hessian_samples': 20,
                    'save_plots': True
                }
                print("ğŸ“Š ConfiguraciÃ³n estÃ¡ndar")
            
            try:
                results = analyze_model_sharpness(args.minima, config=config)
                if results:
                    classification = results.get('sharpness_classification', {})
                    print(f"\nğŸ‰ ANÃLISIS COMPLETADO")
                    print(f"ğŸ·ï¸  CategorÃ­a: {classification.get('category', 'N/A')}")
                    print(f"ğŸ“ˆ Sharpness: {classification.get('overall_sharpness', 0):.4f}")
                    print(f"ğŸ’¡ {classification.get('interpretation', 'N/A')}")
                    return 0
                else:
                    print("âŒ AnÃ¡lisis de minima fallÃ³")
                    return 1
            except Exception as e:
                print(f"âŒ Error en anÃ¡lisis de minima: {e}")
                return 1
        
        # Ablation Study mode (NEW)
        elif args.ablation:
            from analysis.ablation_analyzer import run_quick_ablation_study
            print("ğŸ§ª INICIANDO EXPERIMENTOS DE ABLACIÃ“N...")
            
            # Configure experiment types
            if args.experiments == 'all':
                experiment_types = ['lstm_units', 'lstm_layers', 'dropout_rate', 'embedding_dim']
                print("ğŸ” Experimentos: Todos los componentes")
            else:
                experiment_types = [args.experiments]
                print(f"ğŸ“ Experimento: {args.experiments}")
            
            try:
                results = run_quick_ablation_study(
                    args.ablation, 
                    experiment_types=experiment_types
                )
                
                if results and not results.get('error'):
                    comparative = results.get('comparative_analysis', {})
                    best_overall = comparative.get('best_overall', {})
                    
                    if 'by_perplexity' in best_overall:
                        best = best_overall['by_perplexity']
                        print(f"\nğŸ‰ EXPERIMENTOS COMPLETADOS")
                        print(f"ğŸ† Mejor configuraciÃ³n: {best['variant']}")
                        print(f"ğŸ“ˆ Perplexity: {best['metrics']['perplexity']:.2f}")
                        print(f"ğŸ“Š VisualizaciÃ³n: {results.get('visualization_path', 'N/A')}")
                    return 0
                else:
                    error = results.get('error', 'Error desconocido')
                    print(f"âŒ Experimentos fallaron: {error}")
                    return 1
                    
            except Exception as e:
                print(f"âŒ Error en experimentos de ablaciÃ³n: {e}")
                return 1
        
        # Testing mode (NEW)
        elif args.test:
            print("ğŸ§ª EJECUTANDO SUITE DE TESTS MÃ“DULO 2...")
            
            if args.test == 'quick':
                from testing.module2_test_suite import run_quick_demo
                print("ğŸš€ Modo: Demo rÃ¡pido")
                results = run_quick_demo()
                
            elif args.test == 'full':
                from testing.module2_test_suite import run_full_validation
                print("ğŸ”¬ Modo: ValidaciÃ³n completa")
                results = run_full_validation()
                
            elif args.test == 'selective':
                from testing.module2_test_suite import run_selected_tests
                test_selection = args.test_selection or ['training', 'gradient_analysis']
                print(f"ğŸ¯ Modo: Tests selectivos - {test_selection}")
                results = run_selected_tests(test_selection)
            
            if results and results.get('success'):
                stats = results.get('summary_statistics', {})
                print(f"\nğŸ‰ TESTS COMPLETADOS EXITOSAMENTE")
                print(f"âœ… Ã‰xito: {stats.get('successful_tests', 0)}/{stats.get('total_tests', 0)}")
                print(f"â±ï¸ Tiempo: {stats.get('total_execution_time', 0):.2f}s")
                return 0
            else:
                print(f"\nâŒ ALGUNOS TESTS FALLARON")
                return 1
        
        # Direct training mode - now uses multi-corpus automatically
        elif args.model:
            print(f"ğŸš€ ENTRENAMIENTO MULTI-CORPUS AUTOMÃTICO")
            print(f"   ğŸ“š Usando todos los textos de la carpeta 'corpus/'")
            print(f"   ğŸ¯ Modelo: {args.model}")
            print(f"   ğŸ“Š Ã‰pocas: {args.epochs}")
            return orchestrator.run_corpus_training(args.epochs, args.model)
        
        # Direct generation mode  
        elif args.generate:
            return orchestrator.run_direct_generation(args.generate, args.seed, args.temp, args.length)
        
        # Interactive mode (default)
        else:
            return orchestrator.run_interactive_mode()
    
    except KeyboardInterrupt:
        print("\nğŸ¯ Proceso interrumpido por usuario")
        return 0
    except Exception as e:
        print(f"âŒ Error crÃ­tico: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())